{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import sys\n",
    "from os import path\n",
    "sys.path.append( \"../website/apis/models/\" )\n",
    "\n",
    "from WildfireModel import WildfireModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "IMG_SZ = 100\n",
    "TRAIN_NEW_MODEL = False\n",
    "MODEL_PATH = \"../website/apis/models/wfm.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the linear size of the output layer of a convolutional layer\n",
    "def conv2d_out_sz(in_size, kernel_size, pool_size, padding=0, stride=1):\n",
    "    return ((in_size - kernel_size + 2*padding)/stride + 1)/pool_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5184"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function we just defined\n",
    "# the value of fcin explicitly calculated here is used in the definition of the model in \n",
    "\n",
    "ks = 5 # kernel size\n",
    "ps = 2 # pool size\n",
    "out_chan = 64 # number of output channels \n",
    "\n",
    "os = conv2d_out_sz(IMG_SZ,ks,ps) # outputs to 2nd conv2d layer\n",
    "os = conv2d_out_sz(os,ks,ps) # output size of 2nd conv2d layer\n",
    "os = conv2d_out_sz(os,ks,ps) # output size 3\n",
    "\n",
    "fcin = int((int(os)**2)*out_chan)\n",
    "fcin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((torch.Size([3479, 3, 100, 100]), torch.Size([3479])),\n",
       " (torch.Size([387, 3, 100, 100]), torch.Size([387])))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# must run the Preprocess.ipynb Jupyter Notebook to generate data before running this notebook\n",
    "# load the balanced data array to train and test on\n",
    "data = np.load(\"balanced_data.npy\", allow_pickle=True)\n",
    "extra_data = np.load(\"extra_data.npy\", allow_pickle=True)\n",
    "\n",
    "# format x the way torch wants to see it\n",
    "x = torch.tensor([d[0] for d in data])\n",
    "x = (x/255.0).view(-1,3,100,100)\n",
    "# and the extra x\n",
    "extra_x = torch.tensor([ed[0] for ed in extra_data])\n",
    "extra_x = (extra_x/255.0).view(-1,3,100,100)\n",
    "\n",
    "# format y the way torch wants to see it\n",
    "y = torch.tensor([float(d[1]) for d in data])\n",
    "# and the extra y\n",
    "extra_y = torch.tensor([float(ed[1]) for ed in extra_data])\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.1)\n",
    "(train_x.shape, train_y.shape), (test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(test_x, test_y, wfm):\n",
    "    with torch.no_grad():\n",
    "        y_pred = (np.round(wfm(test_x))).type(torch.FloatTensor)\n",
    "        test_y = test_y.unsqueeze(1)\n",
    "        correct = (y_pred == test_y).type(torch.FloatTensor)\n",
    "        return correct.mean().item() # unpack the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounded buffer class, keeps track of 'size' most recent insertions\n",
    "class BoundedNumericList():\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.nums = []\n",
    "        self.next_insertion = 0\n",
    "        \n",
    "    def insert(self, item):\n",
    "        if not isinstance(item, (int, float, complex)) or isinstance(item, bool):\n",
    "            return False\n",
    "        if len(self.nums) < self.size:\n",
    "            self.nums += [item]\n",
    "        else:\n",
    "            self.nums[self.next_insertion % self.size] = item\n",
    "        self.next_insertion += 1\n",
    "        return True\n",
    "\n",
    "    def average(self):\n",
    "        if len(self.nums) == 0: return None\n",
    "        return sum(self.nums) / len(self.nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_NEW_MODEL:\n",
    "\n",
    "    # instantiate our model, initial optimizer, and loss function\n",
    "    wfm = WildfireModel()\n",
    "    optimizer = optim.AdamW(wfm.parameters(), lr=1e-4)\n",
    "    loss_function = nn.BCELoss()\n",
    "\n",
    "    # declare constants controlling the training process\n",
    "    BATCH_SIZE = 100\n",
    "    EPOCHS = 1000\n",
    "    ROLLING_ACCURACY_SIZE = 4\n",
    "\n",
    "    # instantiate our bounded buffer to keep track of the last ROLLING_ACCURACY_SIZE epochh accuracies\n",
    "    past_epoch_accuracies = BoundedNumericList(ROLLING_ACCURACY_SIZE)\n",
    "    highest_rolling_accuracy = -1\n",
    "\n",
    "    for epoch in range(EPOCHS): # loop over all of our data EPOCH times\n",
    "        for i in range(0, len(train_x), BATCH_SIZE): # iterate over our batches\n",
    "            # grab the ith batch\n",
    "            batch_x = train_x[i : i+BATCH_SIZE]\n",
    "            batch_y = train_y[i : i+BATCH_SIZE]\n",
    "            batch_y = torch.unsqueeze(batch_y, 1)\n",
    "\n",
    "            # zero our gradient\n",
    "            wfm.zero_grad()\n",
    "\n",
    "            # pass the batch through the model\n",
    "            outputs = wfm(batch_x)\n",
    "            \n",
    "            # compute the loss between the outputs and the expected\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            \n",
    "            # update the model's weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # calculate the most recent epoch's accuracy\n",
    "        epoch_accuracy = evaluate_accuracy(test_x, test_y, wfm)\n",
    "        \n",
    "        # add it to the list of past accuracies\n",
    "        past_epoch_accuracies.insert(epoch_accuracy)\n",
    "        \n",
    "        # calculate the rolling average\n",
    "        rolling_accuracy = past_epoch_accuracies.average()\n",
    "\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss}. Rolling Accuracy: {round(rolling_accuracy,3)}\")\n",
    "\n",
    "        # save the model if the most recent updates have been beneficial\n",
    "        if rolling_accuracy > highest_rolling_accuracy:\n",
    "            print(f\"Saving model at epoch {epoch}.\")\n",
    "            torch.save(wfm, MODEL_PATH)\n",
    "            highest_rolling_accuracy = rolling_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test data: 0.9534883499145508\n",
      "Model accuracy on extra data: 0.9596773982048035\n"
     ]
    }
   ],
   "source": [
    "wfm = torch.load(MODEL_PATH)\n",
    "\n",
    "acc = evaluate_accuracy(test_x, test_y, wfm)\n",
    "print(f\"Model accuracy on test data: {acc}\")\n",
    "\n",
    "extra_acc = evaluate_accuracy(extra_x, extra_y, wfm)\n",
    "print(f\"Model accuracy on extra data: {extra_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
