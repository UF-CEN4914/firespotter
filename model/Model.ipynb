{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "from os import path\n",
    "sys.path.append( \"../website/apis/models/\" )\n",
    "\n",
    "from WildfireModel import WildfireModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "IMG_SZ = 100\n",
    "TRAIN_NEW_MODEL = True\n",
    "MODEL_PATH = \"../website/apis/models/wfm.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the linear size of the output layer of a convolutional layer\n",
    "def conv2d_out_sz(in_size, kernel_size, pool_size, padding=0, stride=1):\n",
    "    return ((in_size - kernel_size + 2*padding)/stride + 1)/pool_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5184"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function we just defined\n",
    "# the value of fcin explicitly calculated here is used in the definition of the model in \n",
    "\n",
    "ks = 5 # kernel size\n",
    "ps = 2 # pool size\n",
    "out_chan = 64 # number of output channels \n",
    "\n",
    "os = conv2d_out_sz(IMG_SZ,ks,ps) # outputs to 2nd conv2d layer\n",
    "os = conv2d_out_sz(os,ks,ps) # output size of 2nd conv2d layer\n",
    "os = conv2d_out_sz(os,ks,ps) # output size 3\n",
    "\n",
    "fcin = int((int(os)**2)*out_chan)\n",
    "fcin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the device and the tensor datatype that we will be using, giving preference to NVIDIA GPUs over CPUs\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "torch.set_default_tensor_type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((torch.Size([3479, 3, 100, 100]), torch.Size([3479])),\n",
       " (torch.Size([387, 3, 100, 100]), torch.Size([387])))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# must run the Preprocess.ipynb Jupyter Notebook to generate data before running this notebook\n",
    "# load the balanced data array to train and test on\n",
    "data = np.load(\"balanced_data.npy\", allow_pickle=True)\n",
    "extra_data = np.load(\"extra_data.npy\", allow_pickle=True)\n",
    "\n",
    "# format x the way torch wants to see it\n",
    "x = torch.tensor([d[0] for d in data])\n",
    "x = (x/255.0).view(-1,3,100,100)\n",
    "# and the extra x\n",
    "extra_x = torch.tensor([ed[0] for ed in extra_data])\n",
    "extra_x = (extra_x/255.0).view(-1,3,100,100)\n",
    "\n",
    "# format y the way torch wants to see it\n",
    "y = torch.tensor([float(d[1]) for d in data])\n",
    "# and the extra y\n",
    "extra_y = torch.tensor([float(ed[1]) for ed in extra_data])\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.1)\n",
    "(train_x.shape, train_y.shape), (test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(test_x, test_y, wfm):\n",
    "    with torch.no_grad():\n",
    "        y_pred = wfm(test_x).round()\n",
    "        test_y = test_y.unsqueeze(1)\n",
    "        correct = torch.tensor(y_pred == test_y)\n",
    "        return sum(correct).item()/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounded buffer class, keeps track of 'size' most recent insertions\n",
    "class BoundedNumericList():\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.nums = []\n",
    "        self.next_insertion = 0\n",
    "        \n",
    "    def insert(self, item):\n",
    "        if not isinstance(item, (int, float, complex)) or isinstance(item, bool):\n",
    "            return False\n",
    "        if len(self.nums) < self.size:\n",
    "            self.nums += [item]\n",
    "        else:\n",
    "            self.nums[self.next_insertion % self.size] = item\n",
    "        self.next_insertion += 1\n",
    "        return True\n",
    "\n",
    "    def average(self):\n",
    "        if len(self.nums) == 0: return None\n",
    "        return sum(self.nums) / len(self.nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/.local/lib/python3.8/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "<ipython-input-8-9f96c4b873fa>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct = torch.tensor(y_pred == test_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 0.5216521620750427. Rolling Accuracy: 0.693\n",
      "Saving model at epoch 0.\n",
      "Epoch: 1. Loss: 0.5007863640785217. Rolling Accuracy: 0.708\n",
      "Saving model at epoch 1.\n",
      "Epoch: 2. Loss: 0.4932693839073181. Rolling Accuracy: 0.713\n",
      "Saving model at epoch 2.\n",
      "Epoch: 3. Loss: 0.49051037430763245. Rolling Accuracy: 0.714\n",
      "Saving model at epoch 3.\n",
      "Epoch: 4. Loss: 0.4838408827781677. Rolling Accuracy: 0.72\n",
      "Saving model at epoch 4.\n",
      "Epoch: 5. Loss: 0.4464470148086548. Rolling Accuracy: 0.72\n",
      "Saving model at epoch 5.\n",
      "Epoch: 6. Loss: 0.47642460465431213. Rolling Accuracy: 0.717\n",
      "Epoch: 7. Loss: 0.44293412566185. Rolling Accuracy: 0.717\n",
      "Epoch: 8. Loss: 0.4491131901741028. Rolling Accuracy: 0.716\n",
      "Epoch: 9. Loss: 0.4557952582836151. Rolling Accuracy: 0.717\n",
      "Epoch: 10. Loss: 0.4580579996109009. Rolling Accuracy: 0.724\n",
      "Saving model at epoch 10.\n",
      "Epoch: 11. Loss: 0.48614469170570374. Rolling Accuracy: 0.737\n",
      "Saving model at epoch 11.\n",
      "Epoch: 12. Loss: 0.49574014544487. Rolling Accuracy: 0.758\n",
      "Saving model at epoch 12.\n",
      "Epoch: 13. Loss: 0.2877403497695923. Rolling Accuracy: 0.776\n",
      "Saving model at epoch 13.\n",
      "Epoch: 14. Loss: 0.2608857750892639. Rolling Accuracy: 0.793\n",
      "Saving model at epoch 14.\n",
      "Epoch: 15. Loss: 0.17568284273147583. Rolling Accuracy: 0.807\n",
      "Saving model at epoch 15.\n",
      "Epoch: 16. Loss: 0.16501715779304504. Rolling Accuracy: 0.821\n",
      "Saving model at epoch 16.\n",
      "Epoch: 17. Loss: 0.1658797413110733. Rolling Accuracy: 0.838\n",
      "Saving model at epoch 17.\n",
      "Epoch: 18. Loss: 0.10867565870285034. Rolling Accuracy: 0.852\n",
      "Saving model at epoch 18.\n",
      "Epoch: 19. Loss: 0.12937027215957642. Rolling Accuracy: 0.867\n",
      "Saving model at epoch 19.\n",
      "Epoch: 20. Loss: 0.14011792838573456. Rolling Accuracy: 0.875\n",
      "Saving model at epoch 20.\n",
      "Epoch: 21. Loss: 0.2304152250289917. Rolling Accuracy: 0.875\n",
      "Saving model at epoch 21.\n",
      "Epoch: 22. Loss: 0.2503862977027893. Rolling Accuracy: 0.869\n",
      "Epoch: 23. Loss: 0.15432840585708618. Rolling Accuracy: 0.868\n",
      "Epoch: 24. Loss: 0.1942514330148697. Rolling Accuracy: 0.863\n",
      "Epoch: 25. Loss: 0.15376001596450806. Rolling Accuracy: 0.862\n",
      "Epoch: 26. Loss: 0.08443992584943771. Rolling Accuracy: 0.875\n",
      "Saving model at epoch 26.\n",
      "Epoch: 27. Loss: 0.09650928527116776. Rolling Accuracy: 0.873\n",
      "Epoch: 28. Loss: 0.1227772906422615. Rolling Accuracy: 0.877\n",
      "Saving model at epoch 28.\n",
      "Epoch: 29. Loss: 0.07343920320272446. Rolling Accuracy: 0.884\n",
      "Saving model at epoch 29.\n",
      "Epoch: 30. Loss: 0.08929437398910522. Rolling Accuracy: 0.885\n",
      "Saving model at epoch 30.\n",
      "Epoch: 31. Loss: 0.08630263805389404. Rolling Accuracy: 0.892\n",
      "Saving model at epoch 31.\n",
      "Epoch: 32. Loss: 0.10725566744804382. Rolling Accuracy: 0.893\n",
      "Saving model at epoch 32.\n",
      "Epoch: 33. Loss: 0.07969002425670624. Rolling Accuracy: 0.893\n",
      "Epoch: 34. Loss: 0.06121286749839783. Rolling Accuracy: 0.894\n",
      "Saving model at epoch 34.\n",
      "Epoch: 35. Loss: 0.0944475531578064. Rolling Accuracy: 0.891\n",
      "Epoch: 36. Loss: 0.07534555345773697. Rolling Accuracy: 0.894\n",
      "Epoch: 37. Loss: 0.06430665403604507. Rolling Accuracy: 0.897\n",
      "Saving model at epoch 37.\n",
      "Epoch: 38. Loss: 0.06346339732408524. Rolling Accuracy: 0.899\n",
      "Saving model at epoch 38.\n",
      "Epoch: 39. Loss: 0.07662966102361679. Rolling Accuracy: 0.903\n",
      "Saving model at epoch 39.\n",
      "Epoch: 40. Loss: 0.07627099007368088. Rolling Accuracy: 0.902\n",
      "Epoch: 41. Loss: 0.12384828180074692. Rolling Accuracy: 0.897\n",
      "Epoch: 42. Loss: 0.06259658932685852. Rolling Accuracy: 0.894\n",
      "Epoch: 43. Loss: 0.3649739921092987. Rolling Accuracy: 0.857\n",
      "Epoch: 44. Loss: 0.07208479940891266. Rolling Accuracy: 0.86\n",
      "Epoch: 45. Loss: 0.06683097779750824. Rolling Accuracy: 0.864\n",
      "Epoch: 46. Loss: 0.07762090861797333. Rolling Accuracy: 0.866\n",
      "Epoch: 47. Loss: 0.060153983533382416. Rolling Accuracy: 0.901\n",
      "Epoch: 48. Loss: 0.08239509165287018. Rolling Accuracy: 0.901\n",
      "Epoch: 49. Loss: 0.043527837842702866. Rolling Accuracy: 0.899\n",
      "Epoch: 50. Loss: 0.06873181462287903. Rolling Accuracy: 0.898\n",
      "Epoch: 51. Loss: 0.06134350597858429. Rolling Accuracy: 0.901\n",
      "Epoch: 52. Loss: 0.3817308247089386. Rolling Accuracy: 0.874\n",
      "Epoch: 53. Loss: 0.05677807331085205. Rolling Accuracy: 0.879\n",
      "Epoch: 54. Loss: 0.02857098914682865. Rolling Accuracy: 0.875\n",
      "Epoch: 55. Loss: 0.08138898760080338. Rolling Accuracy: 0.873\n",
      "Epoch: 56. Loss: 0.037559255957603455. Rolling Accuracy: 0.901\n",
      "Epoch: 57. Loss: 0.05565870925784111. Rolling Accuracy: 0.9\n",
      "Epoch: 58. Loss: 0.052976906299591064. Rolling Accuracy: 0.904\n",
      "Saving model at epoch 58.\n",
      "Epoch: 59. Loss: 0.028041226789355278. Rolling Accuracy: 0.902\n",
      "Epoch: 60. Loss: 0.03206538408994675. Rolling Accuracy: 0.904\n",
      "Epoch: 61. Loss: 0.06692755222320557. Rolling Accuracy: 0.903\n",
      "Epoch: 62. Loss: 0.036930497735738754. Rolling Accuracy: 0.906\n",
      "Saving model at epoch 62.\n",
      "Epoch: 63. Loss: 0.02448621392250061. Rolling Accuracy: 0.907\n",
      "Saving model at epoch 63.\n",
      "Epoch: 64. Loss: 0.03415307775139809. Rolling Accuracy: 0.906\n",
      "Epoch: 65. Loss: 0.07661855220794678. Rolling Accuracy: 0.907\n",
      "Epoch: 66. Loss: 0.023276640102267265. Rolling Accuracy: 0.902\n",
      "Epoch: 67. Loss: 0.019190941005945206. Rolling Accuracy: 0.9\n",
      "Epoch: 68. Loss: 0.05433260276913643. Rolling Accuracy: 0.902\n",
      "Epoch: 69. Loss: 0.011361594311892986. Rolling Accuracy: 0.891\n",
      "Epoch: 70. Loss: 0.05119055509567261. Rolling Accuracy: 0.894\n",
      "Epoch: 71. Loss: 0.018330415710806847. Rolling Accuracy: 0.892\n",
      "Epoch: 72. Loss: 0.16070395708084106. Rolling Accuracy: 0.884\n",
      "Epoch: 73. Loss: 0.010404522530734539. Rolling Accuracy: 0.889\n",
      "Epoch: 74. Loss: 0.04622242972254753. Rolling Accuracy: 0.893\n",
      "Epoch: 75. Loss: 0.0316908098757267. Rolling Accuracy: 0.903\n",
      "Epoch: 76. Loss: 0.0987279936671257. Rolling Accuracy: 0.897\n",
      "Epoch: 77. Loss: 0.006241383962333202. Rolling Accuracy: 0.899\n",
      "Epoch: 78. Loss: 0.03136961907148361. Rolling Accuracy: 0.889\n",
      "Epoch: 79. Loss: 0.010372830554842949. Rolling Accuracy: 0.88\n",
      "Epoch: 80. Loss: 0.02969783917069435. Rolling Accuracy: 0.893\n",
      "Epoch: 81. Loss: 0.02251998707652092. Rolling Accuracy: 0.898\n",
      "Epoch: 82. Loss: 0.057316869497299194. Rolling Accuracy: 0.898\n",
      "Epoch: 83. Loss: 0.026232881471514702. Rolling Accuracy: 0.901\n",
      "Epoch: 84. Loss: 0.01357593759894371. Rolling Accuracy: 0.898\n",
      "Epoch: 85. Loss: 0.02109283208847046. Rolling Accuracy: 0.899\n",
      "Epoch: 86. Loss: 0.009722176007926464. Rolling Accuracy: 0.901\n",
      "Epoch: 87. Loss: 0.1364792436361313. Rolling Accuracy: 0.871\n",
      "Epoch: 88. Loss: 0.021984808146953583. Rolling Accuracy: 0.879\n",
      "Epoch: 89. Loss: 0.022286545485258102. Rolling Accuracy: 0.879\n",
      "Epoch: 90. Loss: 0.006761609110981226. Rolling Accuracy: 0.88\n",
      "Epoch: 91. Loss: 0.008569431491196156. Rolling Accuracy: 0.906\n",
      "Epoch: 92. Loss: 0.004069732502102852. Rolling Accuracy: 0.897\n",
      "Epoch: 93. Loss: 0.0062576220370829105. Rolling Accuracy: 0.894\n",
      "Epoch: 94. Loss: 0.15750059485435486. Rolling Accuracy: 0.863\n",
      "Epoch: 95. Loss: 0.011728355661034584. Rolling Accuracy: 0.869\n",
      "Epoch: 96. Loss: 0.007674067281186581. Rolling Accuracy: 0.866\n",
      "Epoch: 97. Loss: 0.03372270613908768. Rolling Accuracy: 0.859\n",
      "Epoch: 98. Loss: 0.004418553784489632. Rolling Accuracy: 0.893\n",
      "Epoch: 99. Loss: 0.012748419307172298. Rolling Accuracy: 0.891\n",
      "Epoch: 100. Loss: 0.014072960242629051. Rolling Accuracy: 0.901\n",
      "Epoch: 101. Loss: 0.021309686824679375. Rolling Accuracy: 0.914\n",
      "Saving model at epoch 101.\n",
      "Epoch: 102. Loss: 0.005325154401361942. Rolling Accuracy: 0.916\n",
      "Saving model at epoch 102.\n",
      "Epoch: 103. Loss: 0.0036978311836719513. Rolling Accuracy: 0.917\n",
      "Saving model at epoch 103.\n",
      "Epoch: 104. Loss: 0.009074299596250057. Rolling Accuracy: 0.917\n",
      "Epoch: 105. Loss: 0.012124204076826572. Rolling Accuracy: 0.915\n",
      "Epoch: 106. Loss: 0.013739429414272308. Rolling Accuracy: 0.919\n",
      "Saving model at epoch 106.\n",
      "Epoch: 107. Loss: 0.0015779356472194195. Rolling Accuracy: 0.921\n",
      "Saving model at epoch 107.\n",
      "Epoch: 108. Loss: 0.002511268714442849. Rolling Accuracy: 0.919\n",
      "Epoch: 109. Loss: 0.002290775068104267. Rolling Accuracy: 0.92\n",
      "Epoch: 110. Loss: 0.006256420630961657. Rolling Accuracy: 0.911\n",
      "Epoch: 111. Loss: 0.0012637772597372532. Rolling Accuracy: 0.91\n",
      "Epoch: 112. Loss: 0.013437353074550629. Rolling Accuracy: 0.911\n",
      "Epoch: 113. Loss: 0.008525225333869457. Rolling Accuracy: 0.913\n",
      "Epoch: 114. Loss: 0.00803903304040432. Rolling Accuracy: 0.922\n",
      "Saving model at epoch 114.\n",
      "Epoch: 115. Loss: 0.005519214551895857. Rolling Accuracy: 0.922\n",
      "Saving model at epoch 115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116. Loss: 0.005764631554484367. Rolling Accuracy: 0.92\n",
      "Epoch: 117. Loss: 0.008570926263928413. Rolling Accuracy: 0.923\n",
      "Saving model at epoch 117.\n",
      "Epoch: 118. Loss: 0.0172397643327713. Rolling Accuracy: 0.922\n",
      "Epoch: 119. Loss: 0.00382635067217052. Rolling Accuracy: 0.929\n",
      "Saving model at epoch 119.\n",
      "Epoch: 120. Loss: 0.00781748816370964. Rolling Accuracy: 0.935\n",
      "Saving model at epoch 120.\n",
      "Epoch: 121. Loss: 0.006375241558998823. Rolling Accuracy: 0.935\n",
      "Epoch: 122. Loss: 0.0018237588228657842. Rolling Accuracy: 0.936\n",
      "Saving model at epoch 122.\n",
      "Epoch: 123. Loss: 0.004078424070030451. Rolling Accuracy: 0.928\n",
      "Epoch: 124. Loss: 0.004775104112923145. Rolling Accuracy: 0.926\n",
      "Epoch: 125. Loss: 0.002644350752234459. Rolling Accuracy: 0.925\n",
      "Epoch: 126. Loss: 0.004019938874989748. Rolling Accuracy: 0.926\n",
      "Epoch: 127. Loss: 0.0016985032707452774. Rolling Accuracy: 0.93\n",
      "Epoch: 128. Loss: 0.004800158552825451. Rolling Accuracy: 0.933\n",
      "Epoch: 129. Loss: 0.003527397522702813. Rolling Accuracy: 0.936\n",
      "Saving model at epoch 129.\n",
      "Epoch: 130. Loss: 0.0048897541128098965. Rolling Accuracy: 0.937\n",
      "Saving model at epoch 130.\n",
      "Epoch: 131. Loss: 0.004293176811188459. Rolling Accuracy: 0.942\n",
      "Saving model at epoch 131.\n",
      "Epoch: 132. Loss: 0.0029740282334387302. Rolling Accuracy: 0.942\n",
      "Epoch: 133. Loss: 0.0022127728443592787. Rolling Accuracy: 0.939\n",
      "Epoch: 134. Loss: 0.01475523505359888. Rolling Accuracy: 0.933\n",
      "Epoch: 135. Loss: 0.0046567367389798164. Rolling Accuracy: 0.935\n",
      "Epoch: 136. Loss: 0.002571424702182412. Rolling Accuracy: 0.935\n",
      "Epoch: 137. Loss: 0.05668862164020538. Rolling Accuracy: 0.916\n",
      "Epoch: 138. Loss: 0.01084300596266985. Rolling Accuracy: 0.917\n",
      "Epoch: 139. Loss: 0.009032129310071468. Rolling Accuracy: 0.914\n",
      "Epoch: 140. Loss: 0.022046299651265144. Rolling Accuracy: 0.908\n",
      "Epoch: 141. Loss: 0.014492232352495193. Rolling Accuracy: 0.924\n",
      "Epoch: 142. Loss: 0.008071331307291985. Rolling Accuracy: 0.928\n",
      "Epoch: 143. Loss: 0.0054008448496460915. Rolling Accuracy: 0.929\n",
      "Epoch: 144. Loss: 0.005355773493647575. Rolling Accuracy: 0.935\n",
      "Epoch: 145. Loss: 0.0021153544075787067. Rolling Accuracy: 0.939\n",
      "Epoch: 146. Loss: 0.006093516480177641. Rolling Accuracy: 0.941\n",
      "Epoch: 147. Loss: 0.009133872576057911. Rolling Accuracy: 0.941\n",
      "Epoch: 148. Loss: 0.003394186496734619. Rolling Accuracy: 0.941\n",
      "Epoch: 149. Loss: 0.00534780602902174. Rolling Accuracy: 0.937\n",
      "Epoch: 150. Loss: 0.0015306827845051885. Rolling Accuracy: 0.937\n",
      "Epoch: 151. Loss: 0.0046387179754674435. Rolling Accuracy: 0.937\n",
      "Epoch: 152. Loss: 0.0010081962682306767. Rolling Accuracy: 0.937\n",
      "Epoch: 153. Loss: 0.0039229062385857105. Rolling Accuracy: 0.938\n",
      "Epoch: 154. Loss: 0.003899364033713937. Rolling Accuracy: 0.936\n",
      "Epoch: 155. Loss: 0.006059704814106226. Rolling Accuracy: 0.937\n",
      "Epoch: 156. Loss: 0.004037171136587858. Rolling Accuracy: 0.938\n",
      "Epoch: 157. Loss: 0.0009108262602239847. Rolling Accuracy: 0.939\n",
      "Epoch: 158. Loss: 0.0010549123398959637. Rolling Accuracy: 0.939\n",
      "Epoch: 159. Loss: 0.0015030986396595836. Rolling Accuracy: 0.941\n",
      "Epoch: 160. Loss: 0.0022297033574432135. Rolling Accuracy: 0.939\n",
      "Epoch: 161. Loss: 0.0010926587274298072. Rolling Accuracy: 0.94\n",
      "Epoch: 162. Loss: 0.0059408703818917274. Rolling Accuracy: 0.936\n",
      "Epoch: 163. Loss: 0.00761847198009491. Rolling Accuracy: 0.935\n",
      "Epoch: 164. Loss: 0.0024020590353757143. Rolling Accuracy: 0.937\n",
      "Epoch: 165. Loss: 0.0006720058736391366. Rolling Accuracy: 0.937\n",
      "Epoch: 166. Loss: 0.0013671371852979064. Rolling Accuracy: 0.945\n",
      "Saving model at epoch 166.\n",
      "Epoch: 167. Loss: 0.00046163483057171106. Rolling Accuracy: 0.945\n",
      "Epoch: 168. Loss: 0.002516207518056035. Rolling Accuracy: 0.942\n",
      "Epoch: 169. Loss: 0.00750302616506815. Rolling Accuracy: 0.934\n",
      "Epoch: 170. Loss: 0.001317361369729042. Rolling Accuracy: 0.933\n",
      "Epoch: 171. Loss: 0.001445294707082212. Rolling Accuracy: 0.935\n",
      "Epoch: 172. Loss: 0.0004208688624203205. Rolling Accuracy: 0.936\n",
      "Epoch: 173. Loss: 0.0002563395828474313. Rolling Accuracy: 0.943\n",
      "Epoch: 174. Loss: 0.0001739207946229726. Rolling Accuracy: 0.939\n",
      "Epoch: 175. Loss: 0.0003641254152171314. Rolling Accuracy: 0.939\n",
      "Epoch: 176. Loss: 0.00034907416556961834. Rolling Accuracy: 0.94\n",
      "Epoch: 177. Loss: 0.00036038411781191826. Rolling Accuracy: 0.941\n",
      "Epoch: 178. Loss: 0.001041098847053945. Rolling Accuracy: 0.933\n",
      "Epoch: 179. Loss: 0.000529864220879972. Rolling Accuracy: 0.932\n",
      "Epoch: 180. Loss: 0.0004303904133848846. Rolling Accuracy: 0.932\n",
      "Epoch: 181. Loss: 0.003804287174716592. Rolling Accuracy: 0.928\n",
      "Epoch: 182. Loss: 0.00027774833142757416. Rolling Accuracy: 0.936\n",
      "Epoch: 183. Loss: 0.00017094259965233505. Rolling Accuracy: 0.937\n",
      "Epoch: 184. Loss: 0.0008001887472346425. Rolling Accuracy: 0.938\n",
      "Epoch: 185. Loss: 0.0009425130556337535. Rolling Accuracy: 0.937\n",
      "Epoch: 186. Loss: 0.000377251417376101. Rolling Accuracy: 0.938\n",
      "Epoch: 187. Loss: 0.005887717008590698. Rolling Accuracy: 0.935\n",
      "Epoch: 188. Loss: 0.00048111137584783137. Rolling Accuracy: 0.933\n",
      "Epoch: 189. Loss: 0.0016352747334167361. Rolling Accuracy: 0.933\n",
      "Epoch: 190. Loss: 2.4847635359037668e-05. Rolling Accuracy: 0.93\n",
      "Epoch: 191. Loss: 8.559364505345002e-05. Rolling Accuracy: 0.93\n",
      "Epoch: 192. Loss: 0.000450916588306427. Rolling Accuracy: 0.929\n",
      "Epoch: 193. Loss: 5.4021322284825146e-05. Rolling Accuracy: 0.93\n",
      "Epoch: 194. Loss: 0.002928395988419652. Rolling Accuracy: 0.931\n",
      "Epoch: 195. Loss: 0.8630647659301758. Rolling Accuracy: 0.901\n",
      "Epoch: 196. Loss: 0.002977100433781743. Rolling Accuracy: 0.899\n",
      "Epoch: 197. Loss: 0.00039775160257704556. Rolling Accuracy: 0.9\n",
      "Epoch: 198. Loss: 0.00011882198305102065. Rolling Accuracy: 0.901\n",
      "Epoch: 199. Loss: 0.00013587131979875267. Rolling Accuracy: 0.933\n",
      "Epoch: 200. Loss: 0.0011514368234202266. Rolling Accuracy: 0.938\n",
      "Epoch: 201. Loss: 0.00020531591144390404. Rolling Accuracy: 0.94\n",
      "Epoch: 202. Loss: 3.095964711974375e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 203. Loss: 2.6309533495805226e-05. Rolling Accuracy: 0.94\n",
      "Epoch: 204. Loss: 5.455261998577043e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 205. Loss: 9.122470510192215e-05. Rolling Accuracy: 0.943\n",
      "Epoch: 206. Loss: 0.00046672759344801307. Rolling Accuracy: 0.94\n",
      "Epoch: 207. Loss: 0.0002944382722489536. Rolling Accuracy: 0.941\n",
      "Epoch: 208. Loss: 3.5004417441086844e-05. Rolling Accuracy: 0.939\n",
      "Epoch: 209. Loss: 7.450777957274113e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 210. Loss: 0.00015696638729423285. Rolling Accuracy: 0.938\n",
      "Epoch: 211. Loss: 1.1317684766254388e-05. Rolling Accuracy: 0.937\n",
      "Epoch: 212. Loss: 3.5581902011472266e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 213. Loss: 9.057622264663223e-06. Rolling Accuracy: 0.936\n",
      "Epoch: 214. Loss: 0.00014798376651015133. Rolling Accuracy: 0.939\n",
      "Epoch: 215. Loss: 0.0002262827765662223. Rolling Accuracy: 0.938\n",
      "Epoch: 216. Loss: 2.6229710783809423e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 217. Loss: 8.420082849625032e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 218. Loss: 2.649953603395261e-05. Rolling Accuracy: 0.943\n",
      "Epoch: 219. Loss: 2.0365920136100613e-05. Rolling Accuracy: 0.947\n",
      "Saving model at epoch 219.\n",
      "Epoch: 220. Loss: 7.269549769262085e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 221. Loss: 2.7988769943476655e-05. Rolling Accuracy: 0.948\n",
      "Saving model at epoch 221.\n",
      "Epoch: 222. Loss: 4.073947820870671e-06. Rolling Accuracy: 0.95\n",
      "Saving model at epoch 222.\n",
      "Epoch: 223. Loss: 3.0425221666519064e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 224. Loss: 8.81144205777673e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 225. Loss: 9.993706044042483e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 226. Loss: 7.275493408087641e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 227. Loss: 2.941398861366906e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 228. Loss: 2.1095204374432797e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 229. Loss: 1.9416636860114522e-05. Rolling Accuracy: 0.939\n",
      "Epoch: 230. Loss: 2.5832616302068345e-05. Rolling Accuracy: 0.939\n",
      "Epoch: 231. Loss: 4.97570681545767e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 232. Loss: 6.452882530538773e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 233. Loss: 2.954324997972435e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 234. Loss: 1.9436330944699876e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 235. Loss: 1.166178833500453e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 236. Loss: 4.6129022734930913e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 237. Loss: 0.0017742777708917856. Rolling Accuracy: 0.939\n",
      "Epoch: 238. Loss: 0.00014477276999969035. Rolling Accuracy: 0.941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 239. Loss: 8.4826506281388e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 240. Loss: 8.184657417587005e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 241. Loss: 5.413968210632447e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 242. Loss: 5.4917181842029095e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 243. Loss: 3.2187615488510346e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 244. Loss: 1.689692794570874e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 245. Loss: 8.785281693235447e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 246. Loss: 2.4904693418648094e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 247. Loss: 9.951456831913674e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 248. Loss: 4.975705110155104e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 249. Loss: 3.368966190464562e-07. Rolling Accuracy: 0.945\n",
      "Epoch: 250. Loss: 0.011716227047145367. Rolling Accuracy: 0.934\n",
      "Epoch: 251. Loss: 0.0002649376692716032. Rolling Accuracy: 0.934\n",
      "Epoch: 252. Loss: 0.0005973384249955416. Rolling Accuracy: 0.931\n",
      "Epoch: 253. Loss: 0.00014718247985001653. Rolling Accuracy: 0.93\n",
      "Epoch: 254. Loss: 1.9482593415887095e-05. Rolling Accuracy: 0.939\n",
      "Epoch: 255. Loss: 2.9621762678289087e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 256. Loss: 1.2720038284896873e-05. Rolling Accuracy: 0.942\n",
      "Epoch: 257. Loss: 1.4562881005986128e-05. Rolling Accuracy: 0.944\n",
      "Epoch: 258. Loss: 3.0036119369469816e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 259. Loss: 4.653936412069015e-05. Rolling Accuracy: 0.945\n",
      "Epoch: 260. Loss: 9.669509381637909e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 261. Loss: 1.1828785318357404e-05. Rolling Accuracy: 0.943\n",
      "Epoch: 262. Loss: 0.26511162519454956. Rolling Accuracy: 0.877\n",
      "Epoch: 263. Loss: 0.001277236850000918. Rolling Accuracy: 0.875\n",
      "Epoch: 264. Loss: 0.004289979115128517. Rolling Accuracy: 0.874\n",
      "Epoch: 265. Loss: 6.464576290454715e-05. Rolling Accuracy: 0.876\n",
      "Epoch: 266. Loss: 4.281218207324855e-05. Rolling Accuracy: 0.943\n",
      "Epoch: 267. Loss: 1.917244662763551e-05. Rolling Accuracy: 0.944\n",
      "Epoch: 268. Loss: 8.430672096437775e-06. Rolling Accuracy: 0.947\n",
      "Epoch: 269. Loss: 3.7577417515421985e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 270. Loss: 6.413236405933276e-05. Rolling Accuracy: 0.944\n",
      "Epoch: 271. Loss: 4.5472766942111775e-05. Rolling Accuracy: 0.943\n",
      "Epoch: 272. Loss: 2.999916068802122e-05. Rolling Accuracy: 0.944\n",
      "Epoch: 273. Loss: 1.1338551303197164e-05. Rolling Accuracy: 0.944\n",
      "Epoch: 274. Loss: 6.605998805753188e-06. Rolling Accuracy: 0.949\n",
      "Epoch: 275. Loss: 3.70075713362894e-06. Rolling Accuracy: 0.95\n",
      "Epoch: 276. Loss: 1.622300487724715e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 277. Loss: 2.008442152146017e-06. Rolling Accuracy: 0.949\n",
      "Epoch: 278. Loss: 2.3491744286729954e-05. Rolling Accuracy: 0.949\n",
      "Epoch: 279. Loss: 0.0004835553700104356. Rolling Accuracy: 0.946\n",
      "Epoch: 280. Loss: 0.00019925559172406793. Rolling Accuracy: 0.946\n",
      "Epoch: 281. Loss: 2.651675822562538e-05. Rolling Accuracy: 0.943\n",
      "Epoch: 282. Loss: 0.00023436042829416692. Rolling Accuracy: 0.94\n",
      "Epoch: 283. Loss: 1.9752684238483198e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 284. Loss: 2.4665923774591647e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 285. Loss: 6.14212331129238e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 286. Loss: 8.871176760294475e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 287. Loss: 4.6078325794951525e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 288. Loss: 2.9362311124714324e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 289. Loss: 7.52605774323456e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 290. Loss: 2.3654254619032145e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 291. Loss: 0.031465861946344376. Rolling Accuracy: 0.932\n",
      "Epoch: 292. Loss: 6.362389285641257e-06. Rolling Accuracy: 0.932\n",
      "Epoch: 293. Loss: 2.887011987695587e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 294. Loss: 1.5782492255311809e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 295. Loss: 1.0910341643466381e-06. Rolling Accuracy: 0.95\n",
      "Saving model at epoch 295.\n",
      "Epoch: 296. Loss: 7.541329978266731e-07. Rolling Accuracy: 0.951\n",
      "Saving model at epoch 296.\n",
      "Epoch: 297. Loss: 6.193731110215595e-07. Rolling Accuracy: 0.952\n",
      "Saving model at epoch 297.\n",
      "Epoch: 298. Loss: 4.716553689831926e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 299. Loss: 1.684499807197426e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 300. Loss: 6.167807100609934e-07. Rolling Accuracy: 0.945\n",
      "Epoch: 301. Loss: 0.0002961020218208432. Rolling Accuracy: 0.933\n",
      "Epoch: 302. Loss: 7.839935278752819e-06. Rolling Accuracy: 0.934\n",
      "Epoch: 303. Loss: 4.568944405036746e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 304. Loss: 1.7907493656821316e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 305. Loss: 1.9799340407189447e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 306. Loss: 1.4020171192896669e-06. Rolling Accuracy: 0.95\n",
      "Epoch: 307. Loss: 9.795953701541293e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 308. Loss: 0.0024624767247587442. Rolling Accuracy: 0.948\n",
      "Epoch: 309. Loss: 0.00013400740863289684. Rolling Accuracy: 0.946\n",
      "Epoch: 310. Loss: 1.2191958376206458e-05. Rolling Accuracy: 0.944\n",
      "Epoch: 311. Loss: 1.56787996274943e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 312. Loss: 8.318784239236265e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 313. Loss: 1.0366030522845904e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 314. Loss: 5.597675567514671e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 315. Loss: 0.00018589984392747283. Rolling Accuracy: 0.946\n",
      "Epoch: 316. Loss: 2.280531248288753e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 317. Loss: 2.643344600983255e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 318. Loss: 3.576289486773021e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 319. Loss: 0.00033932688529603183. Rolling Accuracy: 0.94\n",
      "Epoch: 320. Loss: 2.2287001399945439e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 321. Loss: 3.0579872145608533e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 322. Loss: 1.865888066276966e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 323. Loss: 6.219620019010108e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 324. Loss: 8.81112924844274e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 325. Loss: 2.4878491444724204e-07. Rolling Accuracy: 0.947\n",
      "Epoch: 326. Loss: 2.1380153611971764e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 327. Loss: 7.230600203911308e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 328. Loss: 7.824605563655496e-05. Rolling Accuracy: 0.933\n",
      "Epoch: 329. Loss: 2.1835945517523214e-05. Rolling Accuracy: 0.931\n",
      "Epoch: 330. Loss: 3.1284962460631505e-05. Rolling Accuracy: 0.934\n",
      "Epoch: 331. Loss: 1.5808402622496942e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 332. Loss: 4.098096178495325e-05. Rolling Accuracy: 0.939\n",
      "Epoch: 333. Loss: 1.1551247553143185e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 334. Loss: 5.083038195152767e-05. Rolling Accuracy: 0.943\n",
      "Epoch: 335. Loss: 2.4146424038917758e-05. Rolling Accuracy: 0.946\n",
      "Epoch: 336. Loss: 6.437757747335127e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 337. Loss: 5.634286026179325e-06. Rolling Accuracy: 0.952\n",
      "Saving model at epoch 337.\n",
      "Epoch: 338. Loss: 2.4464470698148943e-06. Rolling Accuracy: 0.952\n",
      "Epoch: 339. Loss: 1.8451895584803424e-06. Rolling Accuracy: 0.952\n",
      "Epoch: 340. Loss: 9.174022466140741e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 341. Loss: 9.898079042613972e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 342. Loss: 2.3323597986291134e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 343. Loss: 2.2530677597387694e-05. Rolling Accuracy: 0.93\n",
      "Epoch: 344. Loss: 1.992882971535437e-06. Rolling Accuracy: 0.926\n",
      "Epoch: 345. Loss: 2.9337996238609776e-05. Rolling Accuracy: 0.919\n",
      "Epoch: 346. Loss: 0.00012292912288103253. Rolling Accuracy: 0.917\n",
      "Epoch: 347. Loss: 2.5268629542551935e-05. Rolling Accuracy: 0.935\n",
      "Epoch: 348. Loss: 7.267162800417282e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 349. Loss: 5.864866125193657e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 350. Loss: 4.436802555574104e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 351. Loss: 2.4256935375888133e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 352. Loss: 2.41013799495704e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 353. Loss: 8.552028134545253e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 354. Loss: 2.150982027160353e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 355. Loss: 1.513454549240123e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 356. Loss: 1.2750309679177008e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 357. Loss: 2.0058639620401664e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 358. Loss: 6.219646024874237e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 359. Loss: 1.3009517942919047e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 360. Loss: 9.329427541615587e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 361. Loss: 9.217819024343044e-05. Rolling Accuracy: 0.943\n",
      "Epoch: 362. Loss: 7.60376042308053e-06. Rolling Accuracy: 0.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 363. Loss: 2.0239792775100796e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 364. Loss: 4.35804613516666e-05. Rolling Accuracy: 0.938\n",
      "Epoch: 365. Loss: 3.7467412767000496e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 366. Loss: 3.602285005399608e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 367. Loss: 3.9651108636462595e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 368. Loss: 2.736685473792022e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 369. Loss: 2.280563876411179e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 370. Loss: 2.285745040353504e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 371. Loss: 7.670913078072772e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 372. Loss: 1.2905829862575047e-06. Rolling Accuracy: 0.947\n",
      "Epoch: 373. Loss: 1.09880818399688e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 374. Loss: 4.820224148716079e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 375. Loss: 7.826397450116929e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 376. Loss: 3.213477839381085e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 377. Loss: 6.012323865434155e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 378. Loss: 3.2031803129939362e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 379. Loss: 8.914867066778243e-07. Rolling Accuracy: 0.945\n",
      "Epoch: 380. Loss: 1.3424173630482983e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 381. Loss: 9.5368329766643e-07. Rolling Accuracy: 0.945\n",
      "Epoch: 382. Loss: 6.73796250794112e-07. Rolling Accuracy: 0.947\n",
      "Epoch: 383. Loss: 3.820027814072091e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 384. Loss: 6.789779831706255e-07. Rolling Accuracy: 0.945\n",
      "Epoch: 385. Loss: 2.9543224400185863e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 386. Loss: 1.8658865030829475e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 387. Loss: 1.295754401553495e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 388. Loss: 1.347584515087874e-07. Rolling Accuracy: 0.947\n",
      "Epoch: 389. Loss: 8.811128537900004e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 390. Loss: 0.00869062915444374. Rolling Accuracy: 0.945\n",
      "Epoch: 391. Loss: 3.179831537636346e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 392. Loss: 9.407220318280451e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 393. Loss: 1.8918012756330427e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 394. Loss: 1.0106879955174009e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 395. Loss: 6.997070300940322e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 396. Loss: 3.1098082331482146e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 397. Loss: 2.332356174861161e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 398. Loss: 1.2957532824486862e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 399. Loss: 7.774519694692117e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 400. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 401. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 402. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 403. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 404. Loss: 3.187610900567961e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 405. Loss: 3.3949349926842842e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 406. Loss: 1.3065287930658087e-05. Rolling Accuracy: 0.937\n",
      "Epoch: 407. Loss: 5.934566615906078e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 408. Loss: 1.9695470143687999e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 409. Loss: 3.990929258179676e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 410. Loss: 3.2134738603417645e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 411. Loss: 2.695170735478314e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 412. Loss: 1.1402635635704428e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 413. Loss: 1.0884333789817902e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 414. Loss: 9.847730098044849e-08. Rolling Accuracy: 0.953\n",
      "Saving model at epoch 414.\n",
      "Epoch: 415. Loss: 8.811125695729061e-08. Rolling Accuracy: 0.953\n",
      "Saving model at epoch 415.\n",
      "Epoch: 416. Loss: 9.329427541615587e-08. Rolling Accuracy: 0.953\n",
      "Epoch: 417. Loss: 9.329427541615587e-08. Rolling Accuracy: 0.95\n",
      "Epoch: 418. Loss: 1.243924288019116e-07. Rolling Accuracy: 0.947\n",
      "Epoch: 419. Loss: 0.00016477557073812932. Rolling Accuracy: 0.941\n",
      "Epoch: 420. Loss: 0.0007125950651243329. Rolling Accuracy: 0.935\n",
      "Epoch: 421. Loss: 1.4201630165189272e-06. Rolling Accuracy: 0.933\n",
      "Epoch: 422. Loss: 1.2180203157186043e-06. Rolling Accuracy: 0.933\n",
      "Epoch: 423. Loss: 7.100765060386038e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 424. Loss: 4.768387498188531e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 425. Loss: 3.47262641753332e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 426. Loss: 2.9543227242356807e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 427. Loss: 9.329428962701058e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 428. Loss: 1.3475842308707797e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 429. Loss: 1.036603123338864e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 430. Loss: 9.847730098044849e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 431. Loss: 6.737919733268427e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 432. Loss: 7.256220868612218e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 433. Loss: 4.664713060265058e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 434. Loss: 5.841593974764692e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 435. Loss: 3.576401468308177e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 436. Loss: 1.8918310615845257e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 437. Loss: 1.6948703205343918e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 438. Loss: 5.183014550880216e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 439. Loss: 1.529006567579927e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 440. Loss: 1.041794007505814e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 441. Loss: 9.277659387407766e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 442. Loss: 4.146411569649899e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 443. Loss: 1.8658867873000418e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 444. Loss: 3.1616448836757627e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 445. Loss: 2.073208236197388e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 446. Loss: 4.7415327571798116e-05. Rolling Accuracy: 0.937\n",
      "Epoch: 447. Loss: 8.052144039538689e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 448. Loss: 2.09913764592784e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 449. Loss: 7.515392326240544e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 450. Loss: 3.7836056776541227e-07. Rolling Accuracy: 0.945\n",
      "Epoch: 451. Loss: 2.1768677527234104e-07. Rolling Accuracy: 0.945\n",
      "Epoch: 452. Loss: 1.3994143444051588e-07. Rolling Accuracy: 0.945\n",
      "Epoch: 453. Loss: 7.774522003956008e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 454. Loss: 6.219617176839165e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 455. Loss: 4.664712349722322e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 456. Loss: 3.628109723763373e-08. Rolling Accuracy: 0.945\n",
      "Epoch: 457. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.945\n",
      "Epoch: 458. Loss: 3.1098082331482146e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 459. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 460. Loss: 2.0732056071892657e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 461. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 462. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 463. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 464. Loss: 5.965837317489786e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 465. Loss: 2.7470014174468815e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 466. Loss: 3.4260874599567614e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 467. Loss: 1.8089033346768701e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 468. Loss: 1.0677117643353995e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 469. Loss: 7.204437224572757e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 470. Loss: 4.489159618970007e-05. Rolling Accuracy: 0.931\n",
      "Epoch: 471. Loss: 9.407202696820605e-07. Rolling Accuracy: 0.933\n",
      "Epoch: 472. Loss: 0.0015128932427614927. Rolling Accuracy: 0.931\n",
      "Epoch: 473. Loss: 7.923647353891283e-05. Rolling Accuracy: 0.933\n",
      "Epoch: 474. Loss: 3.539765748428181e-05. Rolling Accuracy: 0.942\n",
      "Epoch: 475. Loss: 3.178288534400053e-05. Rolling Accuracy: 0.942\n",
      "Epoch: 476. Loss: 1.2697519196080975e-05. Rolling Accuracy: 0.946\n",
      "Epoch: 477. Loss: 7.754428224870935e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 478. Loss: 4.561271907732589e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 479. Loss: 4.188062121102121e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 480. Loss: 1.8503710634831805e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 481. Loss: 3.4001809581241105e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 482. Loss: 6.634301144003985e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 483. Loss: 2.4167209630832076e-05. Rolling Accuracy: 0.946\n",
      "Epoch: 484. Loss: 0.029943101108074188. Rolling Accuracy: 0.932\n",
      "Epoch: 485. Loss: 1.8346285287407227e-05. Rolling Accuracy: 0.932\n",
      "Epoch: 486. Loss: 1.5851981515879743e-05. Rolling Accuracy: 0.931\n",
      "Epoch: 487. Loss: 9.192812285618857e-06. Rolling Accuracy: 0.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 488. Loss: 9.405440323462244e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 489. Loss: 5.198829967412166e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 490. Loss: 4.151767370785819e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 491. Loss: 1.7622546693019103e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 492. Loss: 7.256222289697689e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 493. Loss: 1.969548151237177e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 494. Loss: 6.805807515775086e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 495. Loss: 2.1613625449390383e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 496. Loss: 1.5704770248703426e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 497. Loss: 9.64049263529887e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 498. Loss: 1.1817409131253953e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 499. Loss: 9.145815420197323e-05. Rolling Accuracy: 0.939\n",
      "Epoch: 500. Loss: 1.0890315934375394e-05. Rolling Accuracy: 0.935\n",
      "Epoch: 501. Loss: 1.5893099771346897e-05. Rolling Accuracy: 0.935\n",
      "Epoch: 502. Loss: 1.3853223208570853e-05. Rolling Accuracy: 0.935\n",
      "Epoch: 503. Loss: 2.290924612680101e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 504. Loss: 6.1214304878376424e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 505. Loss: 1.0184679695157683e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 506. Loss: 1.622300032977364e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 507. Loss: 1.7207804603458499e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 508. Loss: 1.4564411685569212e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 509. Loss: 7.981878979990142e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 510. Loss: 7.359913070104085e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 511. Loss: 5.701337499885994e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 512. Loss: 1.3838795211995603e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 513. Loss: 3.2134738603417645e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 514. Loss: 4.975708520760236e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 515. Loss: 5.286692044137453e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 516. Loss: 2.2805286903349042e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 517. Loss: 2.384189485837851e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 518. Loss: 1.3475842308707797e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 519. Loss: 1.347584372979327e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 520. Loss: 8.29282456038527e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 521. Loss: 7.774522714498744e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 522. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 523. Loss: 9.485008831688901e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 524. Loss: 0.00013482292706612498. Rolling Accuracy: 0.935\n",
      "Epoch: 525. Loss: 8.627464012533892e-06. Rolling Accuracy: 0.931\n",
      "Epoch: 526. Loss: 0.0016876152949407697. Rolling Accuracy: 0.93\n",
      "Epoch: 527. Loss: 0.00010718893463490531. Rolling Accuracy: 0.933\n",
      "Epoch: 528. Loss: 5.185398185858503e-05. Rolling Accuracy: 0.938\n",
      "Epoch: 529. Loss: 1.6661097106407396e-05. Rolling Accuracy: 0.944\n",
      "Epoch: 530. Loss: 1.6168569345609285e-05. Rolling Accuracy: 0.946\n",
      "Epoch: 531. Loss: 6.50511492494843e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 532. Loss: 8.51904769660905e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 533. Loss: 2.1820926576765487e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 534. Loss: 5.751115531893447e-05. Rolling Accuracy: 0.946\n",
      "Epoch: 535. Loss: 0.00020578430849127471. Rolling Accuracy: 0.946\n",
      "Epoch: 536. Loss: 0.00011952257045777515. Rolling Accuracy: 0.945\n",
      "Epoch: 537. Loss: 0.00018033146625384688. Rolling Accuracy: 0.943\n",
      "Epoch: 538. Loss: 6.209513958310708e-05. Rolling Accuracy: 0.942\n",
      "Epoch: 539. Loss: 6.765963189536706e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 540. Loss: 2.9542823540396057e-05. Rolling Accuracy: 0.94\n",
      "Epoch: 541. Loss: 5.2662589951069094e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 542. Loss: 9.303564638685202e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 543. Loss: 0.01240044366568327. Rolling Accuracy: 0.926\n",
      "Epoch: 544. Loss: 1.6502111975569278e-05. Rolling Accuracy: 0.926\n",
      "Epoch: 545. Loss: 1.9488527414068813e-06. Rolling Accuracy: 0.926\n",
      "Epoch: 546. Loss: 1.3476026197167812e-06. Rolling Accuracy: 0.927\n",
      "Epoch: 547. Loss: 6.115995461186685e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 548. Loss: 3.939107386941032e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 549. Loss: 2.5915139190146874e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 550. Loss: 2.1250403392514272e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 551. Loss: 1.4512460211335565e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 552. Loss: 1.2439248564533045e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 553. Loss: 8.292828113098949e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 554. Loss: 7.774526267212423e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 555. Loss: 5.18301561669432e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 556. Loss: 5.18301561669432e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 557. Loss: 3.1098089436909504e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 558. Loss: 3.628110434306109e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 559. Loss: 2.0732056071892657e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 560. Loss: 2.591507097804424e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 561. Loss: 2.591507097804424e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 562. Loss: 1.969548151237177e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 563. Loss: 7.774524135584215e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 564. Loss: 3.628110079034741e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 565. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 566. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 567. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 568. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 569. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.939\n",
      "Epoch: 570. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.94\n",
      "Epoch: 571. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 572. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 573. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 574. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 575. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 576. Loss: 0.05557560548186302. Rolling Accuracy: 0.932\n",
      "Epoch: 577. Loss: 5.0664853006310295e-06. Rolling Accuracy: 0.929\n",
      "Epoch: 578. Loss: 1.3243781722849235e-05. Rolling Accuracy: 0.926\n",
      "Epoch: 579. Loss: 9.947016224032268e-06. Rolling Accuracy: 0.925\n",
      "Epoch: 580. Loss: 6.945269319658109e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 581. Loss: 2.487848860255326e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 582. Loss: 3.1875583772489335e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 583. Loss: 4.724533482658444e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 584. Loss: 2.332358519652189e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 585. Loss: 2.7729157636713353e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 586. Loss: 1.891801559850137e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 587. Loss: 1.1661785492833587e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 588. Loss: 1.0625181801060535e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 589. Loss: 1.311319238084252e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 590. Loss: 2.182094249292277e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 591. Loss: 3.9909312476993364e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 592. Loss: 5.286694886308396e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 593. Loss: 2.74700198588107e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 594. Loss: 9.329427541615587e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 595. Loss: 1.2439240038020216e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 596. Loss: 7.774522714498744e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 597. Loss: 4.664712349722322e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 598. Loss: 4.664712349722322e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 599. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 600. Loss: 3.1098089436909504e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 601. Loss: 3.628110079034741e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 602. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 603. Loss: 1.2957542594449478e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 604. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 605. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.942\n",
      "Epoch: 606. Loss: 3.1098082331482146e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 607. Loss: 7.256220868612218e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 608. Loss: 3.628110079034741e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 609. Loss: 2.591507097804424e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 610. Loss: 5.642567703034729e-05. Rolling Accuracy: 0.936\n",
      "Epoch: 611. Loss: 2.975100642288453e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 612. Loss: 2.754807383098523e-06. Rolling Accuracy: 0.932\n",
      "Epoch: 613. Loss: 1.6974501022559707e-06. Rolling Accuracy: 0.928\n",
      "Epoch: 614. Loss: 1.8192557718066382e-06. Rolling Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 615. Loss: 4.5869748532822996e-07. Rolling Accuracy: 0.931\n",
      "Epoch: 616. Loss: 2.384188348969474e-07. Rolling Accuracy: 0.933\n",
      "Epoch: 617. Loss: 2.539678973789705e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 618. Loss: 1.7881409064557374e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 619. Loss: 8.811125695729061e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 620. Loss: 1.1661785492833587e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 621. Loss: 8.29282456038527e-08. Rolling Accuracy: 0.936\n",
      "Epoch: 622. Loss: 6.219617176839165e-08. Rolling Accuracy: 0.936\n",
      "Epoch: 623. Loss: 5.1830138403374804e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 624. Loss: 2.8506574878406354e-08. Rolling Accuracy: 0.936\n",
      "Epoch: 625. Loss: 9.329427541615587e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 626. Loss: 6.997070300940322e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 627. Loss: 5.96046660916727e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 628. Loss: 3.887260646706636e-08. Rolling Accuracy: 0.936\n",
      "Epoch: 629. Loss: 3.887260646706636e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 630. Loss: 2.8506574878406354e-08. Rolling Accuracy: 0.934\n",
      "Epoch: 631. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 632. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 633. Loss: 4.664713060265058e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 634. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 635. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.934\n",
      "Epoch: 636. Loss: 9.847730098044849e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 637. Loss: 4.0945894852484344e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 638. Loss: 4.042763066536281e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 639. Loss: 3.472629259704263e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 640. Loss: 2.5396821001777425e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 641. Loss: 1.9177183219198923e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 642. Loss: 9.35839216253953e-06. Rolling Accuracy: 0.923\n",
      "Epoch: 643. Loss: 2.8057966119376943e-05. Rolling Accuracy: 0.921\n",
      "Epoch: 644. Loss: 7.712689694017172e-06. Rolling Accuracy: 0.923\n",
      "Epoch: 645. Loss: 1.1869151421706192e-06. Rolling Accuracy: 0.921\n",
      "Epoch: 646. Loss: 0.003202225314453244. Rolling Accuracy: 0.933\n",
      "Epoch: 647. Loss: 1.2028068340441678e-05. Rolling Accuracy: 0.937\n",
      "Epoch: 648. Loss: 4.994021765014622e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 649. Loss: 2.8066679078619927e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 650. Loss: 1.6611807041044813e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 651. Loss: 1.205064108944498e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 652. Loss: 8.241056548285997e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 653. Loss: 6.426977279261337e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 654. Loss: 4.768394887832983e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 655. Loss: 3.8354448861355195e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 656. Loss: 3.0579874987779476e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 657. Loss: 2.53968323704612e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 658. Loss: 2.0732097993914067e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 659. Loss: 1.7103975835652818e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 660. Loss: 1.3994157654906303e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 661. Loss: 7.25622371078316e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 662. Loss: 0.0002611383970361203. Rolling Accuracy: 0.938\n",
      "Epoch: 663. Loss: 1.1117662097603898e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 664. Loss: 1.3291221875988413e-05. Rolling Accuracy: 0.937\n",
      "Epoch: 665. Loss: 9.653768756834324e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 666. Loss: 5.851753030583495e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 667. Loss: 3.192772737747873e-06. Rolling Accuracy: 0.936\n",
      "Epoch: 668. Loss: 2.109502247549244e-06. Rolling Accuracy: 0.936\n",
      "Epoch: 669. Loss: 1.207647528644884e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 670. Loss: 6.815679967075994e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 671. Loss: 5.157107807463035e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 672. Loss: 3.4726232911452826e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 673. Loss: 2.539678689572611e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 674. Loss: 1.7103953098285274e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 675. Loss: 1.4512443158309907e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 676. Loss: 5.701315330952639e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 677. Loss: 1.1817346603493206e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 678. Loss: 1.9177159060745907e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 679. Loss: 9.847727966416642e-08. Rolling Accuracy: 0.936\n",
      "Epoch: 680. Loss: 5.701314975681271e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 681. Loss: 4.664712349722322e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 682. Loss: 4.146410503835796e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 683. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 684. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 685. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 686. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 687. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 688. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 689. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.945\n",
      "Epoch: 690. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.946\n",
      "Epoch: 691. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 692. Loss: 0.0. Rolling Accuracy: 0.945\n",
      "Epoch: 693. Loss: 0.030986282974481583. Rolling Accuracy: 0.924\n",
      "Epoch: 694. Loss: 4.799569433089346e-05. Rolling Accuracy: 0.924\n",
      "Epoch: 695. Loss: 3.16069126711227e-05. Rolling Accuracy: 0.924\n",
      "Epoch: 696. Loss: 2.2182768589118496e-05. Rolling Accuracy: 0.926\n",
      "Epoch: 697. Loss: 1.3760228284809273e-05. Rolling Accuracy: 0.949\n",
      "Epoch: 698. Loss: 1.0571897291811183e-05. Rolling Accuracy: 0.95\n",
      "Epoch: 699. Loss: 8.280577276309486e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 700. Loss: 6.3133288676908705e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 701. Loss: 5.406191576184938e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 702. Loss: 3.9962724258657545e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 703. Loss: 3.664533323899377e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 704. Loss: 3.18766183227126e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 705. Loss: 2.6900611374003347e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 706. Loss: 2.3583304482599488e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 707. Loss: 2.1095340798638063e-06. Rolling Accuracy: 0.95\n",
      "Epoch: 708. Loss: 1.4149841263133567e-06. Rolling Accuracy: 0.95\n",
      "Epoch: 709. Loss: 3.6799536928810994e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 710. Loss: 1.3709258155358839e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 711. Loss: 9.846014108916279e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 712. Loss: 2.0472941741900286e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 713. Loss: 1.648225293138239e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 714. Loss: 6.47881165605213e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 715. Loss: 4.457412785541237e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 716. Loss: 7.774524846126951e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 717. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 718. Loss: 1.9695467301517056e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 719. Loss: 5.7013160414953745e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 720. Loss: 3.1098082331482146e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 721. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 722. Loss: 9.225837516169122e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 723. Loss: 1.0884339474159788e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 724. Loss: 1.399415481273536e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 725. Loss: 7.774524846126951e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 726. Loss: 6.737921864896634e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 727. Loss: 5.18301561669432e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 728. Loss: 4.146412280192635e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 729. Loss: 3.628110434306109e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 730. Loss: 3.1098089436909504e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 731. Loss: 3.1098089436909504e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 732. Loss: 2.0732056071892657e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 733. Loss: 2.0732056071892657e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 734. Loss: 2.0732056071892657e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 735. Loss: 7.774524135584215e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 736. Loss: 0.0007190566975623369. Rolling Accuracy: 0.929\n",
      "Epoch: 737. Loss: 9.070304827218933e-07. Rolling Accuracy: 0.925\n",
      "Epoch: 738. Loss: 2.021377270011726e-07. Rolling Accuracy: 0.926\n",
      "Epoch: 739. Loss: 1.9177169008344208e-07. Rolling Accuracy: 0.927\n",
      "Epoch: 740. Loss: 5.183014195608848e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 741. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 742. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 743. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 744. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 745. Loss: 0.0. Rolling Accuracy: 0.942\n",
      "Epoch: 746. Loss: 0.0. Rolling Accuracy: 0.942\n",
      "Epoch: 747. Loss: 0.0. Rolling Accuracy: 0.942\n",
      "Epoch: 748. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 749. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 750. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 751. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 752. Loss: 7.774524135584215e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 753. Loss: 5.7013160414953745e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 754. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 755. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 756. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 757. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 758. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 759. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 760. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 761. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 762. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 763. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 764. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 765. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 766. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 767. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 768. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 769. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 770. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 771. Loss: 1.1564206033654045e-05. Rolling Accuracy: 0.93\n",
      "Epoch: 772. Loss: 0.00019248481839895248. Rolling Accuracy: 0.928\n",
      "Epoch: 773. Loss: 2.7354903068044223e-05. Rolling Accuracy: 0.925\n",
      "Epoch: 774. Loss: 9.65147864917526e-06. Rolling Accuracy: 0.926\n",
      "Epoch: 775. Loss: 4.913696102448739e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 776. Loss: 3.058055881410837e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 777. Loss: 2.0369595858937828e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 778. Loss: 1.332049919255951e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 779. Loss: 9.692316780274268e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 780. Loss: 7.515417337344843e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 781. Loss: 5.442189490167948e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 782. Loss: 4.5092383516021073e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 783. Loss: 3.679950566493062e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 784. Loss: 2.798833804718015e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 785. Loss: 2.487851702426269e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 786. Loss: 2.0732088046315766e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 787. Loss: 1.7622271286654723e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 788. Loss: 1.503075708342294e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 789. Loss: 1.3475847993049683e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 790. Loss: 1.0366035496645054e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 791. Loss: 1.0366034075559583e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 792. Loss: 6.737920443811163e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 793. Loss: 8.811127827357268e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 794. Loss: 7.256222289697689e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 795. Loss: 6.219617887381901e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 796. Loss: 6.219617887381901e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 797. Loss: 3.1098089436909504e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 798. Loss: 4.664713060265058e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 799. Loss: 0.0002568888012319803. Rolling Accuracy: 0.937\n",
      "Epoch: 800. Loss: 0.0002333083830308169. Rolling Accuracy: 0.936\n",
      "Epoch: 801. Loss: 1.1921840268769301e-05. Rolling Accuracy: 0.937\n",
      "Epoch: 802. Loss: 6.0980669331911486e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 803. Loss: 4.480849383980967e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 804. Loss: 3.2886937333387323e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 805. Loss: 2.5060282951017143e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 806. Loss: 1.7363291817673598e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 807. Loss: 1.5082714526215568e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 808. Loss: 1.2180178146081744e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 809. Loss: 1.0417926432637614e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 810. Loss: 8.552019039598235e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 811. Loss: 7.230336791508307e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 812. Loss: 6.297386789810844e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 813. Loss: 4.846132810598647e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 814. Loss: 4.5610650545313547e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 815. Loss: 4.3019124973397993e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 816. Loss: 3.835438917576539e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 817. Loss: 3.1616445994586684e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 818. Loss: 2.9284078095770383e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 819. Loss: 2.487850565557892e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 820. Loss: 2.51376519599944e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 821. Loss: 2.1509532643904095e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 822. Loss: 1.9436320997101575e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 823. Loss: 1.8399717305328522e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 824. Loss: 1.6844806793869793e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 825. Loss: 1.5808204523182212e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 826. Loss: 1.4771597989238217e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 827. Loss: 1.3216691741035902e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 828. Loss: 1.3216691741035902e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 829. Loss: 9.847730098044849e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 830. Loss: 1.1920937481590954e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 831. Loss: 0.005153196398168802. Rolling Accuracy: 0.928\n",
      "Epoch: 832. Loss: 1.6049134501372464e-05. Rolling Accuracy: 0.926\n",
      "Epoch: 833. Loss: 3.1768573535373434e-05. Rolling Accuracy: 0.926\n",
      "Epoch: 834. Loss: 7.619608368258923e-06. Rolling Accuracy: 0.928\n",
      "Epoch: 835. Loss: 7.412258582917275e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 836. Loss: 5.1470001380948815e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 837. Loss: 2.3427778614859562e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 838. Loss: 1.7052406064976822e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 839. Loss: 1.0728950883276411e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 840. Loss: 9.277675871999236e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 841. Loss: 7.256268190758419e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 842. Loss: 3.9909343740873737e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 843. Loss: 3.990933521436091e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 844. Loss: 3.5244588048044534e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 845. Loss: 3.057984940824099e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 846. Loss: 2.591511645277933e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 847. Loss: 1.8658874978427775e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 848. Loss: 1.6585661910539784e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 849. Loss: 1.6067359354110522e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 850. Loss: 1.295754543662042e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 851. Loss: 9.847732229673056e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 852. Loss: 1.1920938902676426e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 853. Loss: 8.811127827357268e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 854. Loss: 8.292825270928006e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 855. Loss: 7.256220868612218e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 856. Loss: 6.737919733268427e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 857. Loss: 6.219617887381901e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 858. Loss: 6.219617887381901e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 859. Loss: 3.628109723763373e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 860. Loss: 5.183014550880216e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 861. Loss: 3.628109723763373e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 862. Loss: 4.1464112143785314e-08. Rolling Accuracy: 0.945\n",
      "Epoch: 863. Loss: 3.628109723763373e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 864. Loss: 0.023639461025595665. Rolling Accuracy: 0.932\n",
      "Epoch: 865. Loss: 7.62434137868695e-05. Rolling Accuracy: 0.93\n",
      "Epoch: 866. Loss: 1.0400922292319592e-05. Rolling Accuracy: 0.928\n",
      "Epoch: 867. Loss: 4.317657840147149e-06. Rolling Accuracy: 0.927\n",
      "Epoch: 868. Loss: 2.5915817332133884e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 869. Loss: 1.6689614312781487e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 870. Loss: 1.176559521809395e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 871. Loss: 6.530643190671981e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 872. Loss: 5.908673301746603e-07. Rolling Accuracy: 0.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 873. Loss: 3.783615341035329e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 874. Loss: 2.643344316766161e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 875. Loss: 1.6585671858138085e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 876. Loss: 1.1402642741131785e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 877. Loss: 8.292828113098949e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 878. Loss: 5.18301561669432e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 879. Loss: 4.146412280192635e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 880. Loss: 3.1098089436909504e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 881. Loss: 2.591507097804424e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 882. Loss: 2.0732056071892657e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 883. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 884. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 885. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 886. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.946\n",
      "Epoch: 887. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.946\n",
      "Epoch: 888. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.946\n",
      "Epoch: 889. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.946\n",
      "Epoch: 890. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.946\n",
      "Epoch: 891. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.946\n",
      "Epoch: 892. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.946\n",
      "Epoch: 893. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 894. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 895. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 896. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 897. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 898. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 899. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 900. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 901. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 902. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 903. Loss: 0.0. Rolling Accuracy: 0.945\n",
      "Epoch: 904. Loss: 0.0. Rolling Accuracy: 0.945\n",
      "Epoch: 905. Loss: 0.0. Rolling Accuracy: 0.945\n",
      "Epoch: 906. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 907. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 908. Loss: 0.008085651323199272. Rolling Accuracy: 0.934\n",
      "Epoch: 909. Loss: 4.315905971452594e-05. Rolling Accuracy: 0.932\n",
      "Epoch: 910. Loss: 3.4416320886521135e-06. Rolling Accuracy: 0.931\n",
      "Epoch: 911. Loss: 3.74486398868612e-06. Rolling Accuracy: 0.93\n",
      "Epoch: 912. Loss: 1.3476019375957549e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 913. Loss: 8.448379276160267e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 914. Loss: 4.923884375784837e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 915. Loss: 3.265307100264181e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 916. Loss: 2.228699429451808e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 917. Loss: 1.6067359354110522e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 918. Loss: 1.1920938902676426e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 919. Loss: 8.811127827357268e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 920. Loss: 6.737919733268427e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 921. Loss: 5.7013160414953745e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 922. Loss: 4.664713060265058e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 923. Loss: 4.1464112143785314e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 924. Loss: 3.628109723763373e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 925. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 926. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 927. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 928. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.934\n",
      "Epoch: 929. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 930. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 931. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.934\n",
      "Epoch: 932. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 933. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 934. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 935. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 936. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 937. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 938. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 939. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.935\n",
      "Epoch: 940. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.935\n",
      "Epoch: 941. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.935\n",
      "Epoch: 942. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 943. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 944. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 945. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 946. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 947. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 948. Loss: 0.0. Rolling Accuracy: 0.936\n",
      "Epoch: 949. Loss: 0.0. Rolling Accuracy: 0.936\n",
      "Epoch: 950. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 951. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 952. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 953. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 954. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 955. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 956. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 957. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 958. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 959. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 960. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 961. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 962. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 963. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 964. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 965. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 966. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 967. Loss: 0.0. Rolling Accuracy: 0.939\n",
      "Epoch: 968. Loss: 0.010290272533893585. Rolling Accuracy: 0.93\n",
      "Epoch: 969. Loss: 3.565100269042887e-05. Rolling Accuracy: 0.929\n",
      "Epoch: 970. Loss: 0.000518400629516691. Rolling Accuracy: 0.924\n",
      "Epoch: 971. Loss: 3.06625479424838e-05. Rolling Accuracy: 0.923\n",
      "Epoch: 972. Loss: 1.713920028123539e-05. Rolling Accuracy: 0.932\n",
      "Epoch: 973. Loss: 9.13298390514683e-06. Rolling Accuracy: 0.934\n",
      "Epoch: 974. Loss: 4.9758773457142524e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 975. Loss: 1.7513444618089125e-05. Rolling Accuracy: 0.939\n",
      "Epoch: 976. Loss: 7.549591373390285e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 977. Loss: 6.657993708358845e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 978. Loss: 4.610490123013733e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 979. Loss: 3.944418040191522e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 980. Loss: 2.5863862447295105e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 981. Loss: 2.5812009880610276e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 982. Loss: 1.7000553498291993e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 983. Loss: 1.9747628812183393e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 984. Loss: 1.4149808293950628e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 985. Loss: 1.1713733556462103e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 986. Loss: 1.0314290648238966e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 987. Loss: 8.292880124827207e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 988. Loss: 8.189217624021694e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 989. Loss: 5.338528126230813e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 990. Loss: 6.478800855802547e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 991. Loss: 5.027542897551029e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 992. Loss: 4.7165596583909064e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 993. Loss: 3.990932953001902e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 994. Loss: 3.5244588048044534e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 995. Loss: 3.2653065318299923e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 996. Loss: 2.747002554315259e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 997. Loss: 2.5396812475264596e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 998. Loss: 2.436020452023513e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 999. Loss: 1.865887071517136e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1000. Loss: 2.3323592301949247e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 1001. Loss: 2.8014794679620536e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 1002. Loss: 0.0002650040842127055. Rolling Accuracy: 0.937\n",
      "Epoch: 1003. Loss: 1.0563820069364738e-05. Rolling Accuracy: 0.939\n",
      "Epoch: 1004. Loss: 1.5886025721556507e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 1005. Loss: 4.268291831976967e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1006. Loss: 1.3269198461784981e-05. Rolling Accuracy: 0.946\n",
      "Epoch: 1007. Loss: 3.827713499049423e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 1008. Loss: 2.684829723875737e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1009. Loss: 1.850349235610338e-06. Rolling Accuracy: 0.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1010. Loss: 1.3786891486233799e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1011. Loss: 1.0573392046353547e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1012. Loss: 8.08552726994094e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1013. Loss: 6.893427553222864e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1014. Loss: 5.338515620678663e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 1015. Loss: 4.612890904809319e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1016. Loss: 3.887266188939975e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1017. Loss: 3.2134727234733873e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1018. Loss: 2.954321303150209e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1019. Loss: 2.5396792580067995e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1020. Loss: 2.0732070993290108e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1021. Loss: 1.9177164745087794e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1022. Loss: 1.762225849688548e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1023. Loss: 1.3475842308707797e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1024. Loss: 1.2439238616934745e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1025. Loss: 1.1920937481590954e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1026. Loss: 8.811125695729061e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1027. Loss: 9.329427541615587e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1028. Loss: 8.29282456038527e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1029. Loss: 7.256220868612218e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1030. Loss: 6.219617176839165e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1031. Loss: 8.29282456038527e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1032. Loss: 2.5915065648973723e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 1033. Loss: 5.183014195608848e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 1034. Loss: 4.664713060265058e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 1035. Loss: 4.1464112143785314e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 1036. Loss: 4.664713060265058e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1037. Loss: 4.1464112143785314e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1038. Loss: 3.628109368492005e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1039. Loss: 4.1464112143785314e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1040. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1041. Loss: 5.7013160414953745e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1042. Loss: 8.583385351812467e-06. Rolling Accuracy: 0.922\n",
      "Epoch: 1043. Loss: 1.6359315850422718e-05. Rolling Accuracy: 0.925\n",
      "Epoch: 1044. Loss: 2.667193257366307e-05. Rolling Accuracy: 0.926\n",
      "Epoch: 1045. Loss: 1.1292066119494848e-05. Rolling Accuracy: 0.927\n",
      "Epoch: 1046. Loss: 7.251388524309732e-06. Rolling Accuracy: 0.947\n",
      "Epoch: 1047. Loss: 5.048425919085275e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1048. Loss: 3.970295892941067e-06. Rolling Accuracy: 0.947\n",
      "Epoch: 1049. Loss: 3.2342736631107982e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1050. Loss: 2.5552719762345077e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 1051. Loss: 2.1976331936457427e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 1052. Loss: 1.7052326484190417e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1053. Loss: 1.606753812666284e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1054. Loss: 1.2283852584005217e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1055. Loss: 1.2905832136311801e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1056. Loss: 1.005512217489013e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1057. Loss: 1.1402734116927604e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1058. Loss: 7.722734949311416e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1059. Loss: 1.0780764796436415e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 1060. Loss: 7.20442812962574e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1061. Loss: 8.552030976716196e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1062. Loss: 5.390355113377154e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1063. Loss: 8.24104688490479e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1064. Loss: 5.494017045748478e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1065. Loss: 6.012325002302532e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1066. Loss: 3.9909312476993364e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1067. Loss: 4.7165588057396235e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1068. Loss: 2.7988323836325435e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1069. Loss: 4.509236930516636e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1070. Loss: 2.74700198588107e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1071. Loss: 3.7836102251276316e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1072. Loss: 2.2805291166605457e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1073. Loss: 2.7988323836325435e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1074. Loss: 1.9695474406944413e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1075. Loss: 3.2653059633958037e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1076. Loss: 1.9695474406944413e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1077. Loss: 1.5549053955510317e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1078. Loss: 1.5030751399081055e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1079. Loss: 1.5030752820166526e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1080. Loss: 1.2957539752278535e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1081. Loss: 5.131199714014656e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1082. Loss: 1.6585656226197898e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1083. Loss: 1.969547156477347e-07. Rolling Accuracy: 0.949\n",
      "Epoch: 1084. Loss: 1.7103960203712631e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1085. Loss: 1.399414486513706e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1086. Loss: 9.847729387502113e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1087. Loss: 9.329426831072851e-08. Rolling Accuracy: 0.947\n",
      "Epoch: 1088. Loss: 1.2439238616934745e-07. Rolling Accuracy: 0.947\n",
      "Epoch: 1089. Loss: 6.219617887381901e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1090. Loss: 9.329426831072851e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1091. Loss: 4.1464112143785314e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1092. Loss: 1.3475842308707797e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1093. Loss: 6.219617887381901e-08. Rolling Accuracy: 0.947\n",
      "Epoch: 1094. Loss: 9.173979833576595e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1095. Loss: 3.2134738603417645e-07. Rolling Accuracy: 0.945\n",
      "Epoch: 1096. Loss: 7.949538121465594e-05. Rolling Accuracy: 0.943\n",
      "Epoch: 1097. Loss: 0.0002710225817281753. Rolling Accuracy: 0.94\n",
      "Epoch: 1098. Loss: 3.911240492016077e-05. Rolling Accuracy: 0.942\n",
      "Epoch: 1099. Loss: 2.512837636459153e-05. Rolling Accuracy: 0.943\n",
      "Epoch: 1100. Loss: 1.582521144882776e-05. Rolling Accuracy: 0.945\n",
      "Epoch: 1101. Loss: 1.1250472198298667e-05. Rolling Accuracy: 0.947\n",
      "Epoch: 1102. Loss: 8.231022547988687e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1103. Loss: 6.499747087218566e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 1104. Loss: 4.623374024959048e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 1105. Loss: 4.136144525546115e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 1106. Loss: 3.4675063034228515e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1107. Loss: 2.8558881695062155e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 1108. Loss: 2.8766201012331294e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 1109. Loss: 2.596728336357046e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 1110. Loss: 2.07841299015854e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 1111. Loss: 1.7000448906401289e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 1112. Loss: 1.6896785837161588e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 1113. Loss: 1.3631430419991375e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 1114. Loss: 1.3268613656691741e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 1115. Loss: 1.1869179843415623e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 1116. Loss: 1.1661857115541352e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 1117. Loss: 8.811166480882093e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1118. Loss: 9.795949154067785e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1119. Loss: 1.0625241202433244e-06. Rolling Accuracy: 0.938\n",
      "Epoch: 1120. Loss: 5.856824145666906e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1121. Loss: 8.552012786822161e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1122. Loss: 7.30807926174748e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1123. Loss: 6.219637498361408e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1124. Loss: 4.1982505649684754e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1125. Loss: 6.58245085105591e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1126. Loss: 6.686111646558857e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1127. Loss: 1.2439240038020216e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1128. Loss: 2.7988315309812606e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1129. Loss: 2.747001133229787e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1130. Loss: 3.783607667173783e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1131. Loss: 3.1616437468073855e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1132. Loss: 3.576285791950795e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1133. Loss: 3.472625564882037e-07. Rolling Accuracy: 0.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1134. Loss: 1.0884333789817902e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 1135. Loss: 5.753164487032336e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 1136. Loss: 3.368964485161996e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 1137. Loss: 2.1768680369405047e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1138. Loss: 5.338519599717984e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 1139. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1140. Loss: 9.847783530858578e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1141. Loss: 1.580833441039431e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 1142. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1143. Loss: 6.54122459309292e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 1144. Loss: 0.004483403638005257. Rolling Accuracy: 0.935\n",
      "Epoch: 1145. Loss: 0.0001402161142323166. Rolling Accuracy: 0.937\n",
      "Epoch: 1146. Loss: 1.7085363651858643e-05. Rolling Accuracy: 0.939\n",
      "Epoch: 1147. Loss: 7.72314888308756e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 1148. Loss: 4.493830147112021e-06. Rolling Accuracy: 0.95\n",
      "Epoch: 1149. Loss: 2.8403558189893374e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 1150. Loss: 2.1924545308138477e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 1151. Loss: 1.736335207169759e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 1152. Loss: 1.3890643231206923e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 1153. Loss: 1.404614749844768e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 1154. Loss: 1.0158800023418735e-06. Rolling Accuracy: 0.951\n",
      "Epoch: 1155. Loss: 5.183036364542204e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1156. Loss: 6.375142902470543e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1157. Loss: 6.219652277650312e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1158. Loss: 6.01233011821023e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1159. Loss: 5.442192332338891e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1160. Loss: 7.670920467717224e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1161. Loss: 5.90867045957566e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1162. Loss: 2.954325850623718e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1163. Loss: 3.5762917605097755e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1164. Loss: 2.9543264190579066e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1165. Loss: 1.0366035496645054e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1166. Loss: 6.271488359743671e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1167. Loss: 4.5610741494783724e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1168. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.949\n",
      "Epoch: 1169. Loss: 8.448390644844039e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1170. Loss: 4.612904547229846e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1171. Loss: 1.0884339474159788e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1172. Loss: 8.241066211667203e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1173. Loss: 1.96954900388846e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1174. Loss: 2.9024963055235276e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1175. Loss: 4.6647137708077935e-08. Rolling Accuracy: 0.95\n",
      "Epoch: 1176. Loss: 5.566910658671986e-06. Rolling Accuracy: 0.95\n",
      "Epoch: 1177. Loss: 1.9177186061369866e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1178. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.95\n",
      "Epoch: 1179. Loss: 3.7215615975583205e-06. Rolling Accuracy: 0.95\n",
      "Epoch: 1180. Loss: 0.0. Rolling Accuracy: 0.949\n",
      "Epoch: 1181. Loss: 9.536846619084827e-07. Rolling Accuracy: 0.949\n",
      "Epoch: 1182. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.949\n",
      "Epoch: 1183. Loss: 8.182154488167726e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 1184. Loss: 2.6951749987347284e-07. Rolling Accuracy: 0.949\n",
      "Epoch: 1185. Loss: 3.82129946956411e-05. Rolling Accuracy: 0.947\n",
      "Epoch: 1186. Loss: 0.01636478304862976. Rolling Accuracy: 0.942\n",
      "Epoch: 1187. Loss: 3.75856579921674e-05. Rolling Accuracy: 0.942\n",
      "Epoch: 1188. Loss: 8.974892807600554e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 1189. Loss: 2.5371232368343044e-06. Rolling Accuracy: 0.94\n",
      "Epoch: 1190. Loss: 1.8218495370092569e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 1191. Loss: 6.971179118409054e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1192. Loss: 7.178504120020079e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1193. Loss: 6.530623863909568e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 1194. Loss: 5.442183237391873e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 1195. Loss: 4.975710226062802e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 1196. Loss: 4.4574056801138795e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 1197. Loss: 3.679949429624685e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 1198. Loss: 4.6647286922052444e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1199. Loss: 3.4726281228358857e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1200. Loss: 2.9543244295382465e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1201. Loss: 3.679950566493062e-07. Rolling Accuracy: 0.949\n",
      "Epoch: 1202. Loss: 2.7470031227494474e-07. Rolling Accuracy: 0.949\n",
      "Epoch: 1203. Loss: 2.3841909069233225e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1204. Loss: 2.2805301114203758e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1205. Loss: 3.7317821011129126e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1206. Loss: 2.43602158889189e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1207. Loss: 1.710396730913999e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1208. Loss: 2.3841909069233225e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1209. Loss: 1.9695484354542714e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1210. Loss: 2.798834657369298e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1211. Loss: 1.7103970151310932e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1212. Loss: 1.6067363617366937e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1213. Loss: 1.0366035496645054e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1214. Loss: 2.487852555077552e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1215. Loss: 1.192094316593284e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1216. Loss: 1.1402640609503578e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1217. Loss: 1.1402640609503578e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1218. Loss: 8.292825981470742e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1219. Loss: 1.1402640609503578e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1220. Loss: 8.292827402556213e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1221. Loss: 9.329431804872002e-08. Rolling Accuracy: 0.95\n",
      "Epoch: 1222. Loss: 7.774524846126951e-08. Rolling Accuracy: 0.95\n",
      "Epoch: 1223. Loss: 4.6647134155364256e-08. Rolling Accuracy: 0.95\n",
      "Epoch: 1224. Loss: 9.847733650758528e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1225. Loss: 2.591507097804424e-08. Rolling Accuracy: 0.949\n",
      "Epoch: 1226. Loss: 3.628110079034741e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1227. Loss: 6.219619308467372e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1228. Loss: 2.591507097804424e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1229. Loss: 5.70131675203811e-08. Rolling Accuracy: 0.945\n",
      "Epoch: 1230. Loss: 3.1098089436909504e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 1231. Loss: 6.737921154353899e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 1232. Loss: 3.628110079034741e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1233. Loss: 3.1098082331482146e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1234. Loss: 3.628110079034741e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 1235. Loss: 8.026487194001675e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1236. Loss: 6.712018603138858e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1237. Loss: 1.6844799688442436e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1238. Loss: 1.114348222586159e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1239. Loss: 1.8140546842460026e-08. Rolling Accuracy: 0.947\n",
      "Epoch: 1240. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1241. Loss: 0.0. Rolling Accuracy: 0.948\n",
      "Epoch: 1242. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 1243. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 1244. Loss: 0.0. Rolling Accuracy: 0.945\n",
      "Epoch: 1245. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1246. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1247. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1248. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1249. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1250. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1251. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1252. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1253. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1254. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1255. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1256. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1257. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1258. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1259. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1260. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1261. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1262. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1263. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1264. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1265. Loss: 0.0. Rolling Accuracy: 0.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1266. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1267. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1268. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1269. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1270. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1271. Loss: 7.774519694692117e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 1272. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1273. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1274. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1275. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1276. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1277. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1278. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1279. Loss: 0.0. Rolling Accuracy: 0.942\n",
      "Epoch: 1280. Loss: 0.0. Rolling Accuracy: 0.94\n",
      "Epoch: 1281. Loss: 0.0016030673868954182. Rolling Accuracy: 0.935\n",
      "Epoch: 1282. Loss: 3.7058694601910247e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 1283. Loss: 2.384192328008794e-07. Rolling Accuracy: 0.938\n",
      "Epoch: 1284. Loss: 1.6067369301708823e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 1285. Loss: 1.0366038338815997e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1286. Loss: 6.219620019010108e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1287. Loss: 5.701317817852214e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1288. Loss: 3.1098089436909504e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1289. Loss: 2.0732056071892657e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1290. Loss: 2.591507097804424e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1291. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1292. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1293. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1294. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 1295. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 1296. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 1297. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1298. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 1299. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 1300. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.943\n",
      "Epoch: 1301. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1302. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1303. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1304. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1305. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1306. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.944\n",
      "Epoch: 1307. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1308. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1309. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1310. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1311. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1312. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1313. Loss: 5.234859941083414e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1314. Loss: 5.167619292478776e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1315. Loss: 1.9985422113677487e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 1316. Loss: 2.36088567362458e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 1317. Loss: 5.208939342082886e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1318. Loss: 4.068672012635943e-07. Rolling Accuracy: 0.944\n",
      "Epoch: 1319. Loss: 2.6692543997342e-07. Rolling Accuracy: 0.947\n",
      "Epoch: 1320. Loss: 1.8918009914159484e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1321. Loss: 1.373499145529422e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1322. Loss: 1.0625181090517799e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1323. Loss: 8.551973706971694e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1324. Loss: 6.737918312182956e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1325. Loss: 4.923862917394217e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1326. Loss: 4.923862917394217e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1327. Loss: 3.36895880082011e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1328. Loss: 2.8506574878406354e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1329. Loss: 2.8506574878406354e-08. Rolling Accuracy: 0.945\n",
      "Epoch: 1330. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 1331. Loss: 1.2957532824486862e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 1332. Loss: 1.2957532824486862e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1333. Loss: 1.2957532824486862e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1334. Loss: 1.2957532824486862e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1335. Loss: 1.2957532824486862e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1336. Loss: 1.2957532824486862e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1337. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1338. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1339. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1340. Loss: 3.628109723763373e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 1341. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1342. Loss: 0.0. Rolling Accuracy: 0.942\n",
      "Epoch: 1343. Loss: 0.0. Rolling Accuracy: 0.942\n",
      "Epoch: 1344. Loss: 4.146411569649899e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 1345. Loss: 2.332356530132529e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 1346. Loss: 1.891822762445372e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 1347. Loss: 2.721085365919862e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1348. Loss: 4.846126557822572e-07. Rolling Accuracy: 0.942\n",
      "Epoch: 1349. Loss: 1.2698390605692111e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1350. Loss: 8.551975838599901e-08. Rolling Accuracy: 0.942\n",
      "Epoch: 1351. Loss: 5.442165473823479e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1352. Loss: 3.628109723763373e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1353. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1354. Loss: 1.8140546842460026e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1355. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1356. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1357. Loss: 7.774519694692117e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1358. Loss: 7.774519694692117e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1359. Loss: 7.774519694692117e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1360. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1361. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1362. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1363. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1364. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1365. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1366. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1367. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1368. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1369. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1370. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1371. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1372. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1373. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1374. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1375. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1376. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1377. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1378. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1379. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1380. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1381. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1382. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1383. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1384. Loss: 3.447400376899168e-05. Rolling Accuracy: 0.935\n",
      "Epoch: 1385. Loss: 0.00011271941912127659. Rolling Accuracy: 0.933\n",
      "Epoch: 1386. Loss: 3.049880797334481e-05. Rolling Accuracy: 0.932\n",
      "Epoch: 1387. Loss: 1.3814242265652865e-05. Rolling Accuracy: 0.93\n",
      "Epoch: 1388. Loss: 8.073082426562905e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 1389. Loss: 5.533122930501122e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 1390. Loss: 3.4753156796796247e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 1391. Loss: 2.6563559458736563e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 1392. Loss: 1.7467031057094573e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 1393. Loss: 1.3475998912326759e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 1394. Loss: 1.0003308261730126e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 1395. Loss: 7.670914783375338e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 1396. Loss: 6.115991482147365e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 1397. Loss: 6.16782131146465e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 1398. Loss: 4.301918750115874e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 1399. Loss: 3.265308805566747e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 1400. Loss: 3.2134784078152734e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 1401. Loss: 2.487852555077552e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 1402. Loss: 1.7622274128825666e-07. Rolling Accuracy: 0.937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1403. Loss: 2.2287005663201853e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 1404. Loss: 1.4512458790250093e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 1405. Loss: 1.2439247143447574e-07. Rolling Accuracy: 0.939\n",
      "Epoch: 1406. Loss: 1.399415481273536e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 1407. Loss: 9.847733650758528e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 1408. Loss: 7.774524846126951e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1409. Loss: 6.219620019010108e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1410. Loss: 5.18301561669432e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1411. Loss: 4.6647137708077935e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1412. Loss: 5.18301561669432e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1413. Loss: 3.628110434306109e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1414. Loss: 3.1098089436909504e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1415. Loss: 3.628110434306109e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 1416. Loss: 2.591507097804424e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1417. Loss: 2.0732056071892657e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1418. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 1419. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 1420. Loss: 9.329431804872002e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1421. Loss: 4.146412280192635e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1422. Loss: 8.292828113098949e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1423. Loss: 1.3190941672291956e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 1424. Loss: 0.00010197440860792994. Rolling Accuracy: 0.941\n",
      "Epoch: 1425. Loss: 5.54077041670098e-06. Rolling Accuracy: 0.939\n",
      "Epoch: 1426. Loss: 1.9643769064714434e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 1427. Loss: 8.215097864194831e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 1428. Loss: 6.21962840341439e-07. Rolling Accuracy: 0.934\n",
      "Epoch: 1429. Loss: 3.291216899015126e-07. Rolling Accuracy: 0.934\n",
      "Epoch: 1430. Loss: 2.513763490696874e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 1431. Loss: 1.6844802530613379e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 1432. Loss: 1.6844802530613379e-07. Rolling Accuracy: 0.936\n",
      "Epoch: 1433. Loss: 1.0625181090517799e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 1434. Loss: 8.551973706971694e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1435. Loss: 1.5030749977995583e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 1436. Loss: 7.256220868612218e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1437. Loss: 5.7013160414953745e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1438. Loss: 4.664713060265058e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1439. Loss: 7.774522714498744e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1440. Loss: 4.664713060265058e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1441. Loss: 3.628109723763373e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1442. Loss: 3.628109723763373e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 1443. Loss: 3.1098082331482146e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1444. Loss: 9.329428962701058e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1445. Loss: 3.628109723763373e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1446. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1447. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1448. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 1449. Loss: 4.664713060265058e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 1450. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1451. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1452. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1453. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1454. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1455. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 1456. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 1457. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 1458. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.938\n",
      "Epoch: 1459. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.938\n",
      "Epoch: 1460. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.938\n",
      "Epoch: 1461. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.938\n",
      "Epoch: 1462. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.938\n",
      "Epoch: 1463. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1464. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.937\n",
      "Epoch: 1465. Loss: 1.6585661910539784e-07. Rolling Accuracy: 0.937\n",
      "Epoch: 1466. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 1467. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 1468. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.934\n",
      "Epoch: 1469. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.934\n",
      "Epoch: 1470. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.935\n",
      "Epoch: 1471. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.935\n",
      "Epoch: 1472. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.935\n",
      "Epoch: 1473. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.935\n",
      "Epoch: 1474. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1475. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.935\n",
      "Epoch: 1476. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1477. Loss: 0.0. Rolling Accuracy: 0.934\n",
      "Epoch: 1478. Loss: 0.0. Rolling Accuracy: 0.934\n",
      "Epoch: 1479. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.934\n",
      "Epoch: 1480. Loss: 0.024141497910022736. Rolling Accuracy: 0.921\n",
      "Epoch: 1481. Loss: 0.00013196580403018743. Rolling Accuracy: 0.922\n",
      "Epoch: 1482. Loss: 3.6852643461315893e-06. Rolling Accuracy: 0.925\n",
      "Epoch: 1483. Loss: 2.44903799284657e-06. Rolling Accuracy: 0.928\n",
      "Epoch: 1484. Loss: 2.17691717807611e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 1485. Loss: 1.6585942148594768e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1486. Loss: 1.3268705743030296e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1487. Loss: 1.124727759815869e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1488. Loss: 9.070364512808737e-07. Rolling Accuracy: 0.947\n",
      "Epoch: 1489. Loss: 8.344728712472715e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1490. Loss: 7.0489528525286e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1491. Loss: 5.960504267932265e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1492. Loss: 5.183042617318279e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1493. Loss: 4.5610744336954667e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1494. Loss: 4.198260512566776e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1495. Loss: 3.6281238635638147e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1496. Loss: 3.3689713063722593e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1497. Loss: 2.9543272717091895e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1498. Loss: 3.3689713063722593e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1499. Loss: 2.5915139190146874e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1500. Loss: 2.073210083608501e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1501. Loss: 1.8140582369596814e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1502. Loss: 1.6067369301708823e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1503. Loss: 1.6067369301708823e-07. Rolling Accuracy: 0.947\n",
      "Epoch: 1504. Loss: 1.347585367739157e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1505. Loss: 1.5030762767764827e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1506. Loss: 1.2439248564533045e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1507. Loss: 1.0884340184702523e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1508. Loss: 1.0884340184702523e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1509. Loss: 9.847735071843999e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1510. Loss: 2.6951749987347284e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1511. Loss: 1.2439248564533045e-07. Rolling Accuracy: 0.946\n",
      "Epoch: 1512. Loss: 9.847735071843999e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1513. Loss: 6.219620019010108e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1514. Loss: 8.292828113098949e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1515. Loss: 6.737921864896634e-08. Rolling Accuracy: 0.946\n",
      "Epoch: 1516. Loss: 7.774526267212423e-08. Rolling Accuracy: 0.945\n",
      "Epoch: 1517. Loss: 6.737921864896634e-08. Rolling Accuracy: 0.945\n",
      "Epoch: 1518. Loss: 8.292828113098949e-08. Rolling Accuracy: 0.945\n",
      "Epoch: 1519. Loss: 5.701317817852214e-08. Rolling Accuracy: 0.945\n",
      "Epoch: 1520. Loss: 1.554906532419409e-07. Rolling Accuracy: 0.945\n",
      "Epoch: 1521. Loss: 5.701317817852214e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 1522. Loss: 5.701317817852214e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 1523. Loss: 6.737921864896634e-08. Rolling Accuracy: 0.945\n",
      "Epoch: 1524. Loss: 4.146412280192635e-08. Rolling Accuracy: 0.944\n",
      "Epoch: 1525. Loss: 9.265621883969288e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 1526. Loss: 7.774526267212423e-08. Rolling Accuracy: 0.943\n",
      "Epoch: 1527. Loss: 0.00020008027786388993. Rolling Accuracy: 0.939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1528. Loss: 5.483387940330431e-05. Rolling Accuracy: 0.935\n",
      "Epoch: 1529. Loss: 2.0499057882261695e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 1530. Loss: 2.498269168427214e-06. Rolling Accuracy: 0.942\n",
      "Epoch: 1531. Loss: 1.575659211994207e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 1532. Loss: 1.1506416512929718e-06. Rolling Accuracy: 0.953\n",
      "Epoch: 1533. Loss: 8.96669178018783e-07. Rolling Accuracy: 0.953\n",
      "Epoch: 1534. Loss: 7.334018050642044e-07. Rolling Accuracy: 0.953\n",
      "Epoch: 1535. Loss: 6.297401000665559e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 1536. Loss: 5.312617759045679e-07. Rolling Accuracy: 0.952\n",
      "Epoch: 1537. Loss: 4.6906498596399615e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1538. Loss: 4.094597727544169e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1539. Loss: 3.6281227266954374e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1540. Loss: 3.2393938909081044e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1541. Loss: 2.928411504399264e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1542. Loss: 2.617429117890424e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1543. Loss: 2.461937924636004e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1544. Loss: 2.721089913393371e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1545. Loss: 2.461937924636004e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1546. Loss: 2.1250403392514272e-07. Rolling Accuracy: 0.949\n",
      "Epoch: 1547. Loss: 1.917718890354081e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1548. Loss: 1.7103975835652818e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1549. Loss: 1.6067369301708823e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1550. Loss: 1.4512460211335565e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1551. Loss: 1.347585367739157e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1552. Loss: 1.2957551120962307e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1553. Loss: 1.7103975835652818e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1554. Loss: 1.554906532419409e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1555. Loss: 1.2957551120962307e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1556. Loss: 1.0884340184702523e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1557. Loss: 9.847735071843999e-08. Rolling Accuracy: 0.949\n",
      "Epoch: 1558. Loss: 9.329432515414737e-08. Rolling Accuracy: 0.95\n",
      "Epoch: 1559. Loss: 9.329432515414737e-08. Rolling Accuracy: 0.95\n",
      "Epoch: 1560. Loss: 9.329432515414737e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1561. Loss: 9.329432515414737e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1562. Loss: 8.811130669528211e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1563. Loss: 8.292828113098949e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1564. Loss: 1.1402642741131785e-07. Rolling Accuracy: 0.951\n",
      "Epoch: 1565. Loss: 8.292828113098949e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1566. Loss: 7.25622371078316e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1567. Loss: 6.737921864896634e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1568. Loss: 6.737921864896634e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1569. Loss: 6.737921864896634e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1570. Loss: 5.701317817852214e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1571. Loss: 5.701317817852214e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1572. Loss: 5.701317817852214e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1573. Loss: 6.219620019010108e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1574. Loss: 5.18301561669432e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1575. Loss: 5.701317817852214e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1576. Loss: 5.18301561669432e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1577. Loss: 6.737921864896634e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1578. Loss: 4.6647137708077935e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1579. Loss: 4.146412280192635e-08. Rolling Accuracy: 0.951\n",
      "Epoch: 1580. Loss: 5.701317817852214e-08. Rolling Accuracy: 0.95\n",
      "Epoch: 1581. Loss: 4.146412280192635e-08. Rolling Accuracy: 0.95\n",
      "Epoch: 1582. Loss: 4.6647137708077935e-08. Rolling Accuracy: 0.949\n",
      "Epoch: 1583. Loss: 4.146412280192635e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1584. Loss: 4.146412280192635e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1585. Loss: 3.628110434306109e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1586. Loss: 3.1098089436909504e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1587. Loss: 3.628110434306109e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1588. Loss: 5.18301561669432e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1589. Loss: 2.591507097804424e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1590. Loss: 4.146412280192635e-08. Rolling Accuracy: 0.947\n",
      "Epoch: 1591. Loss: 2.0732056071892657e-08. Rolling Accuracy: 0.947\n",
      "Epoch: 1592. Loss: 7.25622371078316e-08. Rolling Accuracy: 0.947\n",
      "Epoch: 1593. Loss: 8.499978139298037e-05. Rolling Accuracy: 0.946\n",
      "Epoch: 1594. Loss: 1.8373959846940124e-06. Rolling Accuracy: 0.947\n",
      "Epoch: 1595. Loss: 6.141887070043595e-07. Rolling Accuracy: 0.948\n",
      "Epoch: 1596. Loss: 2.90249118961583e-07. Rolling Accuracy: 0.949\n",
      "Epoch: 1597. Loss: 1.6067353669768636e-07. Rolling Accuracy: 0.95\n",
      "Epoch: 1598. Loss: 9.329427541615587e-08. Rolling Accuracy: 0.949\n",
      "Epoch: 1599. Loss: 6.219617176839165e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1600. Loss: 3.368959156091478e-08. Rolling Accuracy: 0.947\n",
      "Epoch: 1601. Loss: 2.332355997225477e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1602. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.949\n",
      "Epoch: 1603. Loss: 1.8140546842460026e-08. Rolling Accuracy: 0.948\n",
      "Epoch: 1604. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.95\n",
      "Epoch: 1605. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.95\n",
      "Epoch: 1606. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.95\n",
      "Epoch: 1607. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.951\n",
      "Epoch: 1608. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.951\n",
      "Epoch: 1609. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.951\n",
      "Epoch: 1610. Loss: 0.0. Rolling Accuracy: 0.95\n",
      "Epoch: 1611. Loss: 0.0. Rolling Accuracy: 0.949\n",
      "Epoch: 1612. Loss: 0.0. Rolling Accuracy: 0.947\n",
      "Epoch: 1613. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1614. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1615. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1616. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1617. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1618. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1619. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1620. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1621. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1622. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1623. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1624. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1625. Loss: 2.0732086625230295e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1626. Loss: 0.0037191042210906744. Rolling Accuracy: 0.937\n",
      "Epoch: 1627. Loss: 7.448385440511629e-05. Rolling Accuracy: 0.939\n",
      "Epoch: 1628. Loss: 2.125512583006639e-05. Rolling Accuracy: 0.941\n",
      "Epoch: 1629. Loss: 1.4970984011597466e-05. Rolling Accuracy: 0.944\n",
      "Epoch: 1630. Loss: 1.294126923312433e-05. Rolling Accuracy: 0.949\n",
      "Epoch: 1631. Loss: 9.055633199750446e-06. Rolling Accuracy: 0.948\n",
      "Epoch: 1632. Loss: 7.917758011899423e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1633. Loss: 6.30299200565787e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1634. Loss: 5.162582056073006e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1635. Loss: 4.1699308894749265e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1636. Loss: 4.164747679169523e-06. Rolling Accuracy: 0.946\n",
      "Epoch: 1637. Loss: 3.3561289001227124e-06. Rolling Accuracy: 0.945\n",
      "Epoch: 1638. Loss: 2.6563743631413672e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 1639. Loss: 2.174327619286487e-06. Rolling Accuracy: 0.944\n",
      "Epoch: 1640. Loss: 2.0939871774317e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1641. Loss: 1.8374164483248023e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1642. Loss: 1.5808475382073084e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1643. Loss: 1.4564507182512898e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1644. Loss: 1.6274962035822682e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1645. Loss: 1.3761115269517177e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1646. Loss: 1.085854705706879e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1647. Loss: 9.251775736629497e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1648. Loss: 8.733463232601935e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1649. Loss: 8.344730417775281e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1650. Loss: 1.275039835491043e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1651. Loss: 9.796004860618268e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1652. Loss: 8.033744052227121e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1653. Loss: 7.308109388759476e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1654. Loss: 6.997123023211316e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1655. Loss: 6.478813929788885e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1656. Loss: 6.634306828345871e-07. Rolling Accuracy: 0.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1657. Loss: 6.16782926954329e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1658. Loss: 5.856844040863507e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1659. Loss: 5.390367050495115e-07. Rolling Accuracy: 0.943\n",
      "Epoch: 1660. Loss: 2.4309010768774897e-06. Rolling Accuracy: 0.943\n",
      "Epoch: 1661. Loss: 2.539680679092271e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1662. Loss: 0.00014431244926527143. Rolling Accuracy: 0.936\n",
      "Epoch: 1663. Loss: 0.00014617046690545976. Rolling Accuracy: 0.935\n",
      "Epoch: 1664. Loss: 7.2773650572344195e-06. Rolling Accuracy: 0.935\n",
      "Epoch: 1665. Loss: 2.4671628580108518e-06. Rolling Accuracy: 0.937\n",
      "Epoch: 1666. Loss: 1.420161424903199e-06. Rolling Accuracy: 0.941\n",
      "Epoch: 1667. Loss: 7.074851851029962e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1668. Loss: 4.1205086631634913e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1669. Loss: 2.798832952066732e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 1670. Loss: 1.8658873557342304e-07. Rolling Accuracy: 0.94\n",
      "Epoch: 1671. Loss: 1.89180241250142e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1672. Loss: 1.2180090891433792e-07. Rolling Accuracy: 0.941\n",
      "Epoch: 1673. Loss: 8.03367470325611e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1674. Loss: 5.960467319710006e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1675. Loss: 4.923863627936953e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1676. Loss: 3.628110079034741e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1677. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1678. Loss: 4.146411569649899e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1679. Loss: 2.5915069201687402e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1680. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.941\n",
      "Epoch: 1681. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.94\n",
      "Epoch: 1682. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.939\n",
      "Epoch: 1683. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.939\n",
      "Epoch: 1684. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.938\n",
      "Epoch: 1685. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.938\n",
      "Epoch: 1686. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.938\n",
      "Epoch: 1687. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.938\n",
      "Epoch: 1688. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.938\n",
      "Epoch: 1689. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.938\n",
      "Epoch: 1690. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1691. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1692. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1693. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1694. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1695. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1696. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1697. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1698. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1699. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1700. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1701. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1702. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1703. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1704. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1705. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1706. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1707. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1708. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1709. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1710. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1711. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1712. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1713. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1714. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1715. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1716. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1717. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1718. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1719. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1720. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1721. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1722. Loss: 0.00022504734806716442. Rolling Accuracy: 0.93\n",
      "Epoch: 1723. Loss: 2.011034666793421e-06. Rolling Accuracy: 0.928\n",
      "Epoch: 1724. Loss: 8.29282456038527e-08. Rolling Accuracy: 0.926\n",
      "Epoch: 1725. Loss: 2.0213775542288204e-07. Rolling Accuracy: 0.924\n",
      "Epoch: 1726. Loss: 0.0029938840307295322. Rolling Accuracy: 0.929\n",
      "Epoch: 1727. Loss: 0.000345963635481894. Rolling Accuracy: 0.927\n",
      "Epoch: 1728. Loss: 6.492184184025973e-06. Rolling Accuracy: 0.929\n",
      "Epoch: 1729. Loss: 6.375145176207297e-07. Rolling Accuracy: 0.931\n",
      "Epoch: 1730. Loss: 2.539681815960648e-07. Rolling Accuracy: 0.933\n",
      "Epoch: 1731. Loss: 1.0625183932688742e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 1732. Loss: 6.478769165596532e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1733. Loss: 3.887260646706636e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1734. Loss: 2.073205251917898e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1735. Loss: 1.8140546842460026e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1736. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1737. Loss: 7.774519694692117e-09. Rolling Accuracy: 0.934\n",
      "Epoch: 1738. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.935\n",
      "Epoch: 1739. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.937\n",
      "Epoch: 1740. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.937\n",
      "Epoch: 1741. Loss: 0.0. Rolling Accuracy: 0.939\n",
      "Epoch: 1742. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.939\n",
      "Epoch: 1743. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1744. Loss: 2.5915063428527674e-09. Rolling Accuracy: 0.941\n",
      "Epoch: 1745. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1746. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1747. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1748. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1749. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1750. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1751. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1752. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1753. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1754. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1755. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1756. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1757. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1758. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1759. Loss: 0.0. Rolling Accuracy: 0.945\n",
      "Epoch: 1760. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 1761. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 1762. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 1763. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1764. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1765. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1766. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1767. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1768. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1769. Loss: 0.0. Rolling Accuracy: 0.944\n",
      "Epoch: 1770. Loss: 0.0. Rolling Accuracy: 0.945\n",
      "Epoch: 1771. Loss: 0.0. Rolling Accuracy: 0.945\n",
      "Epoch: 1772. Loss: 0.0. Rolling Accuracy: 0.946\n",
      "Epoch: 1773. Loss: 0.0. Rolling Accuracy: 0.945\n",
      "Epoch: 1774. Loss: 0.0. Rolling Accuracy: 0.945\n",
      "Epoch: 1775. Loss: 0.0. Rolling Accuracy: 0.943\n",
      "Epoch: 1776. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1777. Loss: 0.0. Rolling Accuracy: 0.941\n",
      "Epoch: 1778. Loss: 0.0. Rolling Accuracy: 0.939\n",
      "Epoch: 1779. Loss: 0.0. Rolling Accuracy: 0.939\n",
      "Epoch: 1780. Loss: 0.0. Rolling Accuracy: 0.939\n",
      "Epoch: 1781. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1782. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1783. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1784. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1785. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1786. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1787. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1788. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1789. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1790. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1791. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1792. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1793. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1794. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1795. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1796. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1797. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1798. Loss: 0.0. Rolling Accuracy: 0.939\n",
      "Epoch: 1799. Loss: 0.0026576751843094826. Rolling Accuracy: 0.913\n",
      "Epoch: 1800. Loss: 1.1428677453295677e-06. Rolling Accuracy: 0.911\n",
      "Epoch: 1801. Loss: 1.0988115946020116e-06. Rolling Accuracy: 0.909\n",
      "Epoch: 1802. Loss: 2.461998747094185e-06. Rolling Accuracy: 0.905\n",
      "Epoch: 1803. Loss: 1.3890688705942011e-06. Rolling Accuracy: 0.928\n",
      "Epoch: 1804. Loss: 8.759377578826388e-07. Rolling Accuracy: 0.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1805. Loss: 5.234873583503941e-07. Rolling Accuracy: 0.929\n",
      "Epoch: 1806. Loss: 2.8506661919891485e-07. Rolling Accuracy: 0.93\n",
      "Epoch: 1807. Loss: 1.8140582369596814e-07. Rolling Accuracy: 0.932\n",
      "Epoch: 1808. Loss: 1.347585367739157e-07. Rolling Accuracy: 0.933\n",
      "Epoch: 1809. Loss: 9.329432515414737e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 1810. Loss: 8.292828113098949e-08. Rolling Accuracy: 0.935\n",
      "Epoch: 1811. Loss: 4.6647137708077935e-08. Rolling Accuracy: 0.934\n",
      "Epoch: 1812. Loss: 3.628110434306109e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1813. Loss: 3.628110434306109e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1814. Loss: 2.591507097804424e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1815. Loss: 2.0732056071892657e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1816. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1817. Loss: 1.5549041165741073e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1818. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1819. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1820. Loss: 1.036602625958949e-08. Rolling Accuracy: 0.933\n",
      "Epoch: 1821. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.934\n",
      "Epoch: 1822. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.935\n",
      "Epoch: 1823. Loss: 4.4833146262135415e-07. Rolling Accuracy: 0.934\n",
      "Epoch: 1824. Loss: 1.0625181801060535e-07. Rolling Accuracy: 0.935\n",
      "Epoch: 1825. Loss: 7.256220158069482e-08. Rolling Accuracy: 0.937\n",
      "Epoch: 1826. Loss: 0.0. Rolling Accuracy: 0.939\n",
      "Epoch: 1827. Loss: 5.183013129794745e-09. Rolling Accuracy: 0.94\n",
      "Epoch: 1828. Loss: 0.0. Rolling Accuracy: 0.939\n",
      "Epoch: 1829. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1830. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 1831. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1832. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1833. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1834. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1835. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1836. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1837. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1838. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1839. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1840. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1841. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1842. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 1843. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 1844. Loss: 0.0. Rolling Accuracy: 0.936\n",
      "Epoch: 1845. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1846. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1847. Loss: 0.0. Rolling Accuracy: 0.936\n",
      "Epoch: 1848. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 1849. Loss: 0.0. Rolling Accuracy: 0.939\n",
      "Epoch: 1850. Loss: 0.0. Rolling Accuracy: 0.94\n",
      "Epoch: 1851. Loss: 0.0. Rolling Accuracy: 0.94\n",
      "Epoch: 1852. Loss: 0.0. Rolling Accuracy: 0.939\n",
      "Epoch: 1853. Loss: 0.0. Rolling Accuracy: 0.938\n",
      "Epoch: 1854. Loss: 0.0. Rolling Accuracy: 0.937\n",
      "Epoch: 1855. Loss: 0.0. Rolling Accuracy: 0.936\n",
      "Epoch: 1856. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1857. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1858. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1859. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1860. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1861. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1862. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1863. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1864. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1865. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1866. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1867. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1868. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1869. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1870. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1871. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1872. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1873. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1874. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1875. Loss: 0.0. Rolling Accuracy: 0.935\n",
      "Epoch: 1876. Loss: 0.0. Rolling Accuracy: 0.935\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1fdb6735b4c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# update the model's weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if TRAIN_NEW_MODEL:\n",
    "\n",
    "    # instantiate our model, initial optimizer, and loss function\n",
    "    wfm = WildfireModel().to(device)\n",
    "    optimizer = optim.AdamW(wfm.parameters(), lr=1e-4)\n",
    "    loss_function = nn.BCELoss()\n",
    "\n",
    "    # declare constants controlling the training process\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 5000\n",
    "    ROLLING_ACCURACY_SIZE = 4\n",
    "\n",
    "    # instantiate our bounded buffer to keep track of the last ROLLING_ACCURACY_SIZE epochh accuracies\n",
    "    past_epoch_accuracies = BoundedNumericList(ROLLING_ACCURACY_SIZE)\n",
    "    highest_rolling_accuracy = -1\n",
    "\n",
    "    for epoch in range(EPOCHS): # loop over all of our data EPOCH times\n",
    "        for i in range(0, len(train_x), BATCH_SIZE): # iterate over our batches\n",
    "            # grab the ith batch\n",
    "            batch_x = train_x[i : i+BATCH_SIZE]\n",
    "            batch_y = train_y[i : i+BATCH_SIZE]\n",
    "            batch_y = torch.unsqueeze(batch_y, 1)\n",
    "            \n",
    "            # zero our gradient\n",
    "            wfm.zero_grad()\n",
    "\n",
    "            # pass the batch through the model\n",
    "            outputs = wfm(batch_x)\n",
    "            \n",
    "            # compute the loss between the outputs and the expected\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            \n",
    "            # update the model's weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # calculate the most recent epoch's accuracy\n",
    "        epoch_accuracy = evaluate_accuracy(test_x, test_y, wfm)\n",
    "        \n",
    "        # add it to the list of past accuracies\n",
    "        past_epoch_accuracies.insert(epoch_accuracy)\n",
    "        \n",
    "        # calculate the rolling average\n",
    "        rolling_accuracy = past_epoch_accuracies.average()\n",
    "\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss}. Rolling Accuracy: {round(rolling_accuracy,3)}\")\n",
    "\n",
    "        # save the model if the most recent updates have been beneficial\n",
    "        if rolling_accuracy > highest_rolling_accuracy:\n",
    "            print(f\"Saving model at epoch {epoch}.\")\n",
    "            torch.save(wfm, MODEL_PATH)\n",
    "            highest_rolling_accuracy = rolling_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test data: 0.9534883720930233\n",
      "Model accuracy on extra data: 0.9274193548387096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-9f96c4b873fa>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  correct = torch.tensor(y_pred == test_y)\n"
     ]
    }
   ],
   "source": [
    "wfm = torch.load(MODEL_PATH).to(device)\n",
    "\n",
    "acc = evaluate_accuracy(test_x, test_y, wfm)\n",
    "print(f\"Model accuracy on test data: {acc}\")\n",
    "\n",
    "extra_acc = evaluate_accuracy(extra_x, extra_y, wfm)\n",
    "print(f\"Model accuracy on extra data: {extra_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
